\chapter{Akustický model}
\label{kap:akusticky-model}

% - množina fonémů
% - vektorový formát
% - HMM X CNN
% - HTK X Kaldi X sphinx X Bourlard X TensorFlow
% - Monofonémy X trifonémy
% - mixtury
%   - individuální
%   - globální
%   - na monofonémech vs. trifonémech

Koncept celého projektu se zakládá na~přítomnosti automatického přepisu a jeho
následném zdokonalování. Jelikož nebyl k~dispozici uspokojivý hotový nástroj pro
získání automatického přepisu, nezbylo než jej vytvořit.

Zjednodušený řetězec vedoucí od~zvukových dat k~jejich přepisu v~našem případě
vypadá takto:\begin{enumerate}
\item{sběr trénovacích dat,}
\item{stavba akustického modelu,}
\item{stavba jazykového modelu,}
\item{automatické rozpoznávání.}
\end{enumerate}

V tomto řetězci je stavba akustického modelu patrně nevyznamnějším článkem a
sama tvoří řetěz o~mnoha článcích. V~této kapitole pojednáme o~krocích
podniknutých k~jeho sestavení, experimentech a různých volbách.

Do~užšího výběru potenciálních platforem tvorby akustického modelu jsem zařadil
starší systém \textit{HTK}\footnote{hmm toolkit; Hidden Markov Model Toolkit} a
modernější \textit{Kaldi}. HTK pomyslný konkurz nakonec vyhrál díky zkušenostem
Mgr. Nina Peterka, Ph.D. s~tímto systémem, z~níž jsem mohl čerpat.

Akustický model jsem trénoval výhradně z~vlastníh dat. Obětoval jsem tedy
potenciální přínos většího množství trénovacích dat a upřednostnil trénování
přímo na~konkrétního mluvčího.
%TODO: od kdy se vyplatí dělat model na konkrétního mluvčího?

Tvorba akustického modelu probíhala podle návodu v~manuálu k~HTK, \textit{HTK
Book}. V~hrubých rysech probíhá takto:

\begin{enumerate}

\item{Vytvoření počátečních modelů}

Modeluje se skrytými markovovskými řetězci. Všechny fonémy se inicializují jako
shodné. Každý foném je reprezentován pěti stavy (vstupním, výstupním a třemi
vnitřními). Přechodové pravděpodobnosti se nastaví tak, aby byly možné jen
kýžené přechody, to jest ze~vstupního do~druhého a z~každéhu z~vnitřních stavů
do~sebe samého nebo do~následujícího. Konkrétní pravděpodobnosti nejsou
podstatné, ale použil jsem 60\% pro setrvání a 40\% pro postup ve~druhém a
třetím stavu a 70\% pro setrvání a 30\% pro postup ze~čtvrtého do~výstupního.
Střed a variance jsou určeny identicky podle globálního středu a variance.

Kromě vlastních fonémů (viz níže oddíl~\ref{sec:ac:fonetika}) přidám ještě foném
pro~ticho (\textit{sil}).

Pro kódování používám formát MFCC s~první a druhou derivací, nultým koeficientem
a kepstrální normalizací (\texttt{MFCC\_0\_D\_A\_Z} v~notaci HTK).

Následují dvě iterace tréninku Baum-Welchovým algoritmem\cite{welch2003hidden}.

\item{Přidání modelu pro krátkou pauzu}

Z~modelu pro ticho se odvodí model pro krátkou pauzu tak, že se povolí přechod
rovnou z~druhého do~čtvrtého stavu a zpět, aby byl model robustnější a mohl
modelovat pauzu mezi slovy, která je nezřídka nulová.

Trénuje se opět dvěma iteracemi BW-algoritmu.

\item{Nucené zarovnání a odvržení zmetkových vzorků}

Pomocí Viterbiho algoritmu~\cite{forney1973viterbi} se provede tzv.
\textit{forced alignment}, tzn. nucené zarovnání na~úrovni fonémů. Jinými slovy
určí se přesný čas, kde začíná a končí který foném. Při tom se určí hranice, pod
kterou když klesne \textit{likelihood} daného přepisu na~základě odpovídající
nahrávky, tato se z~trénovacích dat odstraní jako pravěpodobně vadná. Následují
další dvě iterace BW-algoritmu.

\item{Přepočítání variance}

Variance modelů byla určena podle původní trénovací sady. Nyní jsme z~ní
vyřadili některé vzorky, proto proběhne její přepočtení, opět následované dvěma
trénovacími iteracemi.

\item{Přechod k~trifonémům}

Z~nuceného zarovnání máme přepis obohacený o~konkrétní fonetické realizace. Z~té
se nyní snadno vytvoří transkripce trifonémová tak, že ke každému fonému přidáme
jeho levý a pravý kontext, pokud nejsou na~začátku nebo na~konci věty.

Je-li fonémů 45, pak trifonémů je až $45^3 = 91125$. Ne všechny se v~trénovacích
datech objeví. V~praxi jich mám kolem 14 tisíc. Pokud by každý trifoném měl
vlastní separátní model, došlo by k~opačnému problému než v~případě monofonémů,
totiž že by celkový model měl příliš mnoho parametrů. Přechodové matice mohou
všechny trifonémy odvozené od jednoho monofonému sdílet. Avšak které trifonémy
mají sdílet varianci a které mají mít vlastní, je třeba rozhodnout opatrněji.

Pro určení, které modely je vhodné sloučit, používám rozhodovací stromy.
Na~základě předem definovaných kritérií se u~každého emitujícího stavu každé
skupiny trifonémů provede rozdělení na~dva shluky, což umožní zvýšení
\textit{log likelihood} dat. Vybere se kritérium, které ji zvýší nejvíce a
postup se opakuje, dokud zvýšení neklesne pod~danou hranici. Takto získané
shluky se pak sloučí do jednoho logického trifonému.

\item{Štěpení mixtur}

Posledním krokem ve~zvětšování komplexity modelu je štěpení tzv.~\textit{mixtur}
(z~angl. \textit{mixtures}). Spočívá v~tom, že se přesněji modelují variantní
realizace jednotlivých fonémů. Daný foném pak není modelován jednou gaußovskou
distribucí, nýbrž složením několika. Každá má svůj střed, svoji varianci a svoji
váhu, jejichž celkový součet musí být roven jedné.

Rozštěpení u~jednoho modelu proběhne tak, že se mixtura s~největší vahou
rozštěpí na dvě totožné, jen jedna dostane malinko větší váhu než druhá, aby se
při trénování mohly rozejít. To se provede u~všech vnitřích stavů všech
logických fonémů, t.j. u~všech markovovských modelů, provedou se čtyři trénovací
iterace a úspěšnost se vyhodnotí na~sadě heldout.

Pokud u~některé mixtury klesne její váha pod~daný práh, vymaže se, čímž se
zamezí zbytečnému nárůstu parametrů a není proto potřeba zkoušet štěpit
jednotlivé modely samostatně. Arci, takovým způsobem jsem nikdy nedosáhl lepšího
výsledku, než štěpením všech modelů najednou.

Závislost úspěšnosti na~počtu mixtur není monotónní, proto ve~štěpení pokračuji,
i když někdy úspěšnost klesne. Konkrétně zastavím štěpení, pokud úspěšnost
klesne o~více než 30\% oproti nejvyšší dosažené nebo pokud klesne více než
třikrát za~sebou, ale nikdy když je mixtur méně než 16.

\end{enumerate}

Blíže popíšu jen rozhodnutí, která nejsou zřejmá.

\section{Segmentace}

Zpravidla jeden zvukový soubor odpovídá jednomu přetočení magnetofonové pásky,
obvyklá délka je tedy 45 až 120 minut. Takto dlouhé úseky nelze použít ani jako
trénovací příklady ani jako cíl automatického rozpoznávání.

Celá aplikace je pojata jako nástroj pro~zdokonalování automatického přepisu,
takže vychází z~předpokladu, že nějaký přepis již existuje. Vycházeje z~téhož
předpokladu při~segmentaci, realizoval jsem ji tak, že zvukový soubor se rozdělí
na~úseky odpovídající jednotlivým větám v~přepisu, ne však delší než patnáct
sekund. Pokud by věta byla delší, rozdělí se u nejbližšího slova
před~patnáctisekundovou hranicí.

V~případě, že pro daný záznam zatím žádný přepis neexistuje, rozdělí se naivně
na~patnáctisekundové úseky.

Nutno dodat, že rozdělování podle automaticky rozpoznaných hranic vět by šlo
snadno vylepšit. Jde-li o~ručně přepsaná data, jsou hranice vět dobrým vodítkem,
ale u~automaticky přepsaných by bylo lépe rozdělovat podle ticha mezi slovy.

\section{Fonetika}
\label{sec:ac:fonetika}

Množinu fonémů jsem použil od~doc. Pavla Ircinga ze~Západočeské univerzity
z~jeho skriptů z~devadesátých let minulého století. Fonémy mají tzv. pražský a
plzeňský zápis. V~souladu se~zjevným územ jsem použil plzeňský zápis.
V~tabulce~\ref{tab:phones} jsou uvedeny.

\begin{table}[htpb]
\fontspec{DoulosSIL}
\begin{center}
\begin{tabular}{|l|l|l|l||l|l|l|l|}
\hline
IPA & plz. & praž. & grafém & IPA & plz. & praž. & grafém \\
\hline
% TODO: IPA
a  & a   & a   & a      &     ɱ  & mg  & mg  & tra\underline{m}vaj \\
aː & aa  & aa  & á      &     n  & n   & n   & \underline{n}e \\
aʊ̯ & aw  & au  & au     &     ŋ  & ng  & ng  & pa\underline{n}t \\
b  & b   & b   & b      &     ɲ  & nj  & nj  & \v{n} \\
t͡s & c   & c   & c      &     o  & o   & o   & o \\
t͡ʃ & ch  & cz  & č      &     oː & oo  & oo  & ó \\
d  & d   & d   & d      &     oʊ̯ & ow  & ou  & ou \\
ɟ  & dj  & dj  & \v{d}  &     p  & p   & p   & p \\
d͡z & dz  & dz  & dz     &     r  & r   & r   & r \\
d͡ʒ & dzh & dzz & dž     &     r̝̊  & rsh & rsz & t\underline{\v{r}}i \\
ɛ  & e   & e   & e      &     r̝  & rzh & rzz & \underline{\v{r}}íz \\
ɛː & ee  & ee  & é      &     s  & s   & s   & s \\
eʊ̯ & ew  & eu  & eu     &     ʃ  & sh  & sz  & š \\
f  & f   & f   & f      &     t  & t   & t   & t \\
g  & g   & g   & g      &     c  & tj  & tj  & \v{t} \\
ɦ  & h   & h   & h      &     ʊ  & u   & u   & u \\
i  & i   & i   & i      &     uː & uu  & uu  & ú, \r{u} \\
iː & ii  & ii  & í      &     v  & v   & v   & v \\
j  & j   & j   & j      &     x  & x   & ch  & ch \\
k  & k   & k   & k      &     z  & z   & z   & z \\
l  & l   & l   & l      &     ʒ  & zh  & zz  & ž \\
m  & m   & m   & \underline{m}ák
                        &        &     &     & \\
\hline
\end{tabular}
\caption{použité fonémy: IPA, plzeňský zápis, pražský zápis a nejčastější
odpovídající grafém}\label{tab:phones}
\end{center}
\end{table}
\normalfont

V~závislosti na~množství trénovacích dat bylo vhodné nahradit některé fonémy
častějšími podobnými. V~tabulce~\ref{tab:phonesed} jsou záměny vyčísleny.
\begin{table}[htpb]
\fontspec{DoulosSIL}
\begin{center}
\begin{tabular}{|r|l|l||l|l|}
\hline
&
\multicolumn{2}{|c||}{před záměnou} &
\multicolumn{2}{|c|}{po záměně} \\
\hline
& IPA & plz. & IPA & plz. \\
\hline
    & ɱ  & mg & m & m \\
    & aʊ̯ & aw & a ʊ & a u \\
    & oː & oo & o & o \\
\** & d͡z & dz & t͡s & c \\
    & d͡ʒ & dzh & t͡ʃ & ch \\
\** & eʊ̯ & ew & ɛ ʊ & e u \\
\hline
\end{tabular}
\caption{použité záměny fonémů; hvězdičkou jsou vyznačeny záměny použité ještě
v~době psaní textu}\label{tab:phonesed}
\end{center}
\end{table}
\normalfont

% Vyslov.pm, psql

\section{Rozdělení dat}

Pro natrénování modelu strojovým učením je potřeba trénovacích dat a pro
vyhodnocení jeho úspěšnosti dat testovacích, která ve~fázi trénování nesmí být
algoritmem spatřena. Při trénování samotném se pak mnohdy používá vyhrazených,
tzv.~\textit{heldout} dat pro průběžné měření úspěšnosti. V~případě trénování
akustického modelu s~použitím HTK je tomu nejinak. Heldout data jsou používána
pro zjištění optimálního počtu mixtur modelů jednotlivých fonémů, a testovací
pro závěrečné vyhodnocení.

Anotovaná data mi přibývala velice pozvolna a začínal jsem s~několika minutami,
ovšem přírůstky byly časté. Nemohl jsem si tedy dovolit udělat od~začátku pevnou
testovací sadu, kterou bych používal po~celou dobu provádění experimentů. Místo
toho jsem s~každou novou dávkou anotovaných dat celou sadu rozdělil podle vět
v~poměru 18:1:1 do trénovací, heldout a testovací sady. Tak jsem měl neustále
vyvážený poměr jednotlivých datových sad. Zřejmou velkou nevýhodou bylo, že
nešlo spolehlivě porovnávat výsledky jednotlivých experimentů vzhledem
k~variabilní testovací sadě.

Až když jsem měl několik desítek hodin anotovaných dat, vyhradil jsem si fixní
testovací sadu. Běžně se testovací sada vybere jako náhodná podmnožina vzorků
z~trénovací sady tak, aby měla kýženou velikost. V~mém případě vzorků zvíci
hodinových nahrávek jsem sadu určil manuálně jako úsek druhé až jedenácté minuty
(tedy deset minut minutu po~začátku) v~pěti nahrávkách,
\begin{enumerate}
\item{jedné kazety z~roku 1976,}
\item{jedné z~roku 1982,}
\item{jedné z~roku 1986,}
\item{jedné z~roku 1990 a}
\item{jednoho nedatovaného kotouče.}
\end{enumerate}

Sadu heldout nyní vybírám jako každou čtyřicátou větu. Z~každé dvacáté jsem
snížil na~polovic nejen abych neplýtval trénovacími daty, nýbrž také protože
vyhodnocování mixtur zabírá při trénování zdaleka nejvíce času, a ten je přímo
úměrný velikosti sady heldout.

\section{Spojování trifonémů}

% triphone-tree
% neznámé trifonémy
