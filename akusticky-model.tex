\chapter{Automatický přepis}
\label{kap:asr}

% - množina fonémů
% - vektorový formát
% - HMM X CNN
% - HTK X Kaldi X sphinx X Bourlard X TensorFlow
% - Monofonémy X trifonémy
% - mixtury
%   - individuální
%   - globální
%   - na monofonémech vs. trifonémech

Koncept celého projektu se zakládá na~přítomnosti počátečního přepisu a jeho
následném zdokonalování. Pro získání počátečního přepisu bylo nutné sestavit
systém pro automatický přepis, z~historických důvodů častěji označovaný jako
rozpoznávání řeči. Rozpoznávání češtiny se věnovali mnozí přede mnou,
například Ircing et al. 2001\cite{ircing2001large}, Psutka et al.
2005\cite{psutka2005automatic}, či Byrne et al. 1999\cite{byrne1999large}.
V následujících odstavcích popíšu tvorbu rozpoznávače řeči pro korpus Karla
Makoně.

Zjednodušený řetězec vedoucí od~zvukových dat k~jejich přepisu v~našem případě
vypadá takto:\begin{enumerate}
\item{sběr trénovacích dat,}
\item{stavba akustického modelu,}
\item{stavba jazykového modelu,}
\item{automatické rozpoznávání.}
\end{enumerate}

První trénovací sadu jsem pořídil svépomocí přepisem asi 15 minut nahrávky
\texttt{85-05A}.

\section{Základní tvorba akustického modelu}

Do~užšího výběru potenciálních platforem tvorby akustického modelu jsem zařadil
starší systém \textit{HTK}\footnote{HMM ToolKit; HMM = Hidden Markov Model}\cite{young2002htk} a
modernější \textit{Kaldi}\cite{povey2011kaldi}. HTK pomyslný konkurz nakonec vyhrál díky zkušenostem
mého konzultanta Mgr. Nina Peterka, Ph.D. s~tímto systémem, z~nichž jsem mohl
čerpat.

Akustický model jsem trénoval výhradně z~vlastních dat.
% Obětoval jsem tedy
% potenciální přínos většího množství trénovacích dat a upřednostnil trénování
% přímo na~konkrétního mluvčího.
%TODO: od kdy se vyplatí dělat model na konkrétního mluvčího?

Tvorba akustického modelu probíhala podle návodu v~manuálu k~HTK, \textit{HTK
Book}. V~hrubých rysech probíhá takto:

\begin{enumerate}

\item{Vytvoření počátečních modelů}

Modeluje se skrytými markovovskými řetězci. Všechny fonémy se inicializují jako
shodné. Každý foném je reprezentován pěti stavy (vstupním, výstupním a třemi
vnitřními). Přechodové pravděpodobnosti se nastaví tak, aby byly možné jen
kýžené přechody, to jest ze~vstupního do~druhého a z~každéhu z~vnitřních stavů
do~sebe samého nebo do~následujícího. Konkrétní pravděpodobnosti nejsou
podstatné, ale použil jsem 60\% pro setrvání a 40\% pro postup ve~druhém a
třetím stavu a 70\% pro setrvání a 30\% pro postup ze~čtvrtého do~výstupního.
Střed a variance jsou určeny identicky podle globálních hodnot.

Kromě vlastních fonémů (viz níže sekci~\ref{sec:ac:fonetika}) přidám ještě foném
pro~ticho (\texttt{sil}).

Pro kódování používám formát MFCC s~první a druhou derivací, nultým koeficientem
a kepstrální normalizací (\texttt{MFCC\_0\_D\_A\_Z} v~notaci HTK).

Následují dvě iterace tréninku Baum-Welchovým algoritmem\cite{welch2003hidden}.

\item{Přidání modelu pro krátkou pauzu}

Z~modelu pro ticho se odvodí model pro krátkou pauzu tak, že se povolí přechod
rovnou z~druhého do~čtvrtého stavu a zpět, aby byl model robustnější a mohl
modelovat pauzu mezi slovy, která je nezřídka nulová.

Trénuje se opět dvěma iteracemi BW-algoritmu.

\item{Nucené zarovnání a odvržení zmetkových vzorků}

Pomocí Viterbiho algoritmu\cite{forney1973viterbi} se provede tzv.
\textit{forced alignment}, tzn. nucené zarovnání na~úrovni fonémů. Jinými slovy
určí se přesný čas, kde začíná a končí který foném. Při tom se určí hranice, pod
kterou když klesne \textit{likelihood} daného přepisu na~základě odpovídající
nahrávky, tato se z~trénovacích dat odstraní jako pravěpodobně vadná. Následují
další dvě iterace BW-algoritmu.

\item{Přepočítání variance}

Variance modelů byla určena podle původní trénovací sady. Nyní jsme z~ní
vyřadili některé vzorky, proto proběhne její přepočtení, opět následované dvěma
trénovacími iteracemi.

\item{Přechod k~trifonémům}
\label{item:htktrain:triphones}

Z~nuceného zarovnání máme přepis obohacený o~konkrétní fonetické realizace. Z~té
se nyní snadno vytvoří přepis trifonémový tak, že ke každému fonému přidáme
jeho levý a pravý kontext, pokud nejsou na~začátku nebo na~konci věty.

Je-li fonémů 45, pak trifonémů je až $45^3 = 91125$. Ne všechny se v~trénovacích
datech objeví. V~praxi jich mám kolem 14 tisíc. Pokud by každý trifoném měl
vlastní separátní model, došlo by k~opačnému problému než v~případě monofonémů,
totiž že by celkový model měl příliš mnoho parametrů. Přechodové matice mohou
všechny trifonémy odvozené od jednoho monofonému sdílet. Avšak které trifonémy
mají sdílet varianci a které mají mít vlastní, je třeba rozhodnout opatrněji.

Pro určení, které modely je vhodné sloučit, používám rozhodovací stromy.
Na~základě předem definovaných kritérií se u~každého emitujícího stavu každé
skupiny trifonémů provede rozdělení na~dva shluky, což umožní zvýšení
\textit{log likelihood} dat. Vybere se kritérium, které ji zvýší nejvíce a
postup se opakuje, dokud zvýšení neklesne pod~danou hranici. Takto získané
shluky se pak sloučí do jednoho logického trifonému.

\item{Štěpení mixtur}

Posledním krokem ve~zvětšování komplexity modelu je štěpení tzv.~\textit{mixtur}
(z~angl. \textit{mixtures}). Spočívá v~tom, že se přesněji modelují variantní
realizace jednotlivých fonémů. Daný foném v~jednom stavu HMM pak není modelován jednou gaußovskou
distribucí, nýbrž složením několika. Každá má svůj střed, svoji varianci a svoji
váhu, jejichž celkový součet musí být roven jedné.

Štěpí se vnitřní stavové modely jednotlivých fonémů. Optimální počet
mixtur je tedy potřeba zjistit pro trojnásobek počtu použitých trifonémů. To
jsou řádově tisíce až desítky tisíc. V~okamžiku psaní tohoto textu používám 8444
reálných trifonémů, 13746, počítám-li i ty virtuální. To znamená přes dvacet pět
tisíc distribucí, u~nichž je potřeba určit optimální počet mixtur.

Aby byl úkol aspoň aproximací dosažitelný, je třeba hledat efektivněji než
prohledáváním celého prostoru hrubou silou. První pomocí zde je, že modely jsou
na sobě více méné nezávislé: Nalezneme-li optimální počet mixtur pro jeden
z~nich, nemělo by to ovlivnit optimální počet mixtur u~jiného.

Rozštěpení u~jednoho modelu proběhne tak, že se mixtura s~největší vahou
rozštěpí na dvě totožné, jen jedna dostane malinko větší váhu než druhá, aby se
při trénování mohly rozejít. To se provede u~všech vnitřích stavů všech
logických fonémů, t.j. u~všech markovovských modelů. Provedou se čtyři trénovací
iterace a úspěšnost se vyhodnotí na~sadě heldout.

Pokud u~některé mixtury klesne její váha pod~daný práh, vymaže se, čímž se
zamezí zbytečnému nárůstu parametrů a není proto potřeba zkoušet štěpit
jednotlivé modely samostatně. Arci, štěpením modelů jednoho po druhém jsem nikdy nedosáhl lepšího
výsledku, než štěpením všech modelů najednou.

Závislost úspěšnosti na~počtu mixtur není monotónní, proto ve~štěpení pokračuji,
i když někdy úspěšnost klesne. Konkrétně zastavím štěpení, pokud úspěšnost
klesne o~více než 30\% oproti nejvyšší dosažené nebo pokud klesne více než
třikrát za~sebou, ale nikdy když je mixtur méně než 16.

%Pokud je foném gaußiánem modelován dobře, rozdělení na dvě mixtury
%nijak nepomůže. Navíc pokud rozdělíme dostribuci příliš, dojde snadno
%k~přetrénování. Je proto potřeba nalézt optimální počet mixtur pro každý
%jednotlivý trifoném.

\end{enumerate}

\section{Segmentace}

Zpravidla jeden zvukový soubor odpovídá jednomu přetočení magnetofonové pásky,
obvyklá délka je tedy 45 až 120 minut. Takto dlouhé úseky nelze použít ani jako
trénovací příklady ani jako cíl automatického rozpoznávání.

Celá aplikace je pojata jako nástroj pro~zdokonalování automatického přepisu,
takže vychází z~předpokladu, že nějaký přepis již existuje. Vycházeje z~téhož
předpokladu při~segmentaci, realizoval jsem ji tak, že zvukový soubor se rozdělí
na~úseky odpovídající jednotlivým větám v~přepisu, ne však delší než patnáct
sekund. Pokud by věta byla delší, rozdělí se u nejbližšího slova
před~patnáctisekundovou hranicí.

V~případě, že pro daný záznam zatím žádný přepis neexistuje, rozdělí se naivně
na~patnáctisekundové úseky.

Nutno dodat, že rozdělování podle automaticky rozpoznaných hranic vět by šlo
snadno vylepšit. Jde-li o~ručně přepsaná data, jsou hranice vět dobrým vodítkem,
ale u~automaticky přepsaných by bylo lépe rozdělovat podle ticha mezi slovy.

\section{Fonetika}
\label{sec:ac:fonetika}

\subsection{Fonetický přepis}

Trénovací data pro akustické modelování pomocí HTK mají formu párů
parametrizovaných zvukových souborů (v~mém případě MFCC) a textových souborů,
obsahujících fonetický přepis. Ten se může získat různými způsoby. Lze ručně
anotovat data do~fonetického i běžného přepisu, což je zdlouhavé a náročné. Běžně
se trénovací přepisy do fonetických převádějí automaticky. U jazyků
s~nepravidelnou výslovností, jako je angličtina, je často nejlepší použít
robustní výslovnostní slovník a v~případě jeho nedostatečnosti se uchýlit
k~pravidlové výslovnosti, popř. anotovat mimoslovníková slova ručně.

Čeština skýtá se svojí téměř deterministickou a navíc relativně jednoduchou
fonetikou možnost používat primárně pravidlový přepis. Výjimky pak lze ošetřit
slovníkem. Vzhledem k~tomu, že slovní zásoba Karla Makoně je svérázná a
netypická, vydal jsem se právě touto cestou, neboť i kvalitní robustní slovník
by zde byl nedostatečný a svou obsáhlostí zbytečný.

Pro podrobnější popis získávání fonetického přepisu viz sekci~\ref{ssec:porizeni-fonetickeho-prepisu}.

\subsection{Fonémy}

% TODO cite

Používám základní fonémy českého jazyka\cite{palkova1992fonetika}
reprezentované pomocí PACal\cite{nouza1997phonetic}. Kromě základních fonémů
používám dvojhlásky, ticho a krátkou pauzu. Ráz (glotální plozivu) nevyznačuji,
jakož ani neřečové události.
V~tabulce~\ref{tab:phones} jsou fonémy uvedeny.

\begin{table}[htpb]
\fontspec{DoulosSIL}
\begin{center}
\begin{tabular}{|l|l|l||l|l|l|}
\hline
IPA & PACal & grafém & IPA & PACal & grafém \\
\hline
a  & a   & a      &     ɱ  & mg  & tra\underline{m}vaj \\
aː & aa  & á      &     n  & n   & \underline{n}e \\
aʊ̯ & aw  & au     &     ŋ  & ng  & ta\underline{n}k \\
b  & b   & b      &     ɲ  & nj  & \v{n} \\
t͡s & c   & c      &     o  & o   & o \\
t͡ʃ & ch  & č      &     oː & oo  & ó \\
d  & d   & d      &     oʊ̯ & ow  & ou \\
ɟ  & dj  & \v{d}  &     p  & p   & p \\
d͡z & dz  & dz     &     r  & r   & r \\
d͡ʒ & dzh & dž     &     r̝̊  & rsh & t\underline{\v{r}}i \\
ɛ  & e   & e      &     r̝  & rzh & \underline{\v{r}}íz \\
ɛː & ee  & é      &     s  & s   & s \\
eʊ̯ & ew  & eu     &     ʃ  & sh  & š \\
f  & f   & f      &     t  & t   & t \\
g  & g   & g      &     c  & tj  & \v{t} \\
ɦ  & h   & h      &     ʊ  & u   & u \\
i  & i   & i      &     uː & uu  & ú, \r{u} \\
iː & ii  & í      &     v  & v   & v \\
j  & j   & j      &     x  & x   & ch \\
k  & k   & k      &     z  & z   & z \\
l  & l   & l      &     ʒ  & zh  & ž \\
m  & m   & \underline{m}ák
                  &        & sil & \\
   &     &        &        & sp  & \\
\hline
\end{tabular}
\caption{použité fonémy: IPA, PACal a nejčastější odpovídající
grafém}\label{tab:phones}
\end{center}
\end{table}
\normalfont

V~závislosti na~množství trénovacích dat bylo vhodné nahradit některé fonémy
častějšími podobnými. V~tabulce~\ref{tab:phonesed} jsou záměny vyčísleny.
\begin{table}[htpb]
\fontspec{DoulosSIL}
\begin{center}
\begin{tabular}{|r|l|l||l|l|}
\hline
&
\multicolumn{2}{|c||}{před záměnou} &
\multicolumn{2}{|c|}{po záměně} \\
\hline
& IPA & PACal & IPA & PACal \\
\hline
    & ɱ  & mg & m & m \\
    & aʊ̯ & aw & a ʊ & a u \\
    & oː & oo & o & o \\
\** & d͡z & dz & t͡s & c \\
    & d͡ʒ & dzh & t͡ʃ & ch \\
\** & eʊ̯ & ew & ɛ ʊ & e u \\
\hline
\end{tabular}
\caption{použité záměny fonémů; hvězdičkou jsou vyznačeny záměny použité ještě
v~době psaní textu}\label{tab:phonesed}
\end{center}
\end{table}
\normalfont

\section{Rozdělení dat}

Pro natrénování modelu strojovým učením je potřeba trénovacích dat a pro
vyhodnocení jeho úspěšnosti dat testovacích, která ve~fázi trénování nesmí být
algoritmem spatřena. Při trénování samotném se pak mnohdy používá vyhrazených,
tzv.~\textit{heldout} dat pro průběžné měření úspěšnosti. V~případě trénování
akustického modelu s~použitím HTK je tomu nejinak. Heldout data jsou používána
pro zjištění optimálního počtu mixtur modelů jednotlivých fonémů, a testovací
pro závěrečné vyhodnocení.

Anotovaná data mi přibývala velice pozvolna a začínal jsem s~několika minutami,
ovšem přírůstky byly časté. Nemohl jsem si tedy dovolit udělat od~začátku pevnou
testovací sadu, kterou bych používal po~celou dobu provádění experimentů. Místo
toho jsem s~každou novou dávkou anotovaných dat celou sadu rozdělil podle vět
v~poměru 18:1:1 do trénovací, heldout a testovací sady. Tak jsem měl neustále
vyvážený poměr jednotlivých datových sad. Zřejmou velkou nevýhodou bylo, že
nešlo spolehlivě porovnávat výsledky jednotlivých experimentů vzhledem
k~variabilní testovací sadě.

Až když jsem měl několik desítek hodin anotovaných dat, vyhradil jsem si fixní
testovací sadu. Běžně se testovací sada vybere jako náhodná podmnožina vzorků
z~trénovací sady tak, aby měla kýženou velikost. V~mém případě vzorků zvíci
hodinových nahrávek jsem sadu určil manuálně jako úsek druhé až jedenácté minuty
(tedy deset minut minutu po~začátku) v~pěti nahrávkách,
\begin{enumerate}
\item{jedné kazety z~roku 1976,}
\item{jedné z~roku 1982,}
\item{jedné z~roku 1986,}
\item{jedné z~roku 1990 a}
\item{jednoho nedatovaného kotouče.}
\end{enumerate}

Sadu heldout nyní vybírám jako každou čtyřicátou větu. Z~každé dvacáté jsem
snížil na~polovic nejen abych neplýtval trénovacími daty, nýbrž také protože
vyhodnocování mixtur zabírá při trénování zdaleka nejvíce času, a ten je přímo
úměrný velikosti sady heldout.

\section{Spojování trifonémů}

Pro slučování modelů jednotlivých trifonémů, jak zmiňuje
bod~\ref{item:htktrain:triphones} seznamu kroků trénování pomocí~HTK, je
zapotřebí rozhodovacích stromů. Pro jejich tvorbu je potřeba ručně vytvořit
otázky, na základě nichž bude algoritmus dělit fonémy do shluků. K~tvorbě
otázek můžeme použít lingvisticky motivovanou kategorizaci v~naději, že aspoň
některé lingvistikou definované kategorie budou tvořit konzistentní shluky
z~pohledu trénovacích dat. Pro tvorbu otázek jsem vycházel z~předlohy pro
angličtinu, jak je v HTK Book a z~kategorizace českých hlásek na Wikipedii ({\em
https://cs.wikipedia.org/wiki/Fonologie~češtiny}).
% TODO otázky do apendixu

\section{Experiment s kepstrální normalizací}
\label{sec:mfcc-norm}

Kepstrální normalizace je standardní technikou pro kompenzaci různorodých
akustických podmínek v~rámci trénovacích a testovacích dat, viz Viikki a Laurila
1998\cite{viikki1998cepstral}. Princip této techniky spočívá v~tom, že se ode
všech melfrekvenčních kepstrálních koeficientů odečte jejich průměr z~akusticky
konzistentního úseku. Já toto poněkud hrubiánsky činím na celých nahrávkách,
které nejsou vždy akusticky konzistentní, ale často ano a nalezení akusticky
podobných množin je jedním z~mých plánů pro budoucí práci.

Nabízí se však otázka, zda má smysl odečítat průměr z~celé nahrávky, nebo by to
mělo být jen z~řečových událostí, tedy s~vynechaným tichem (šumem, hluky atd.)
Tato idea, přišedší ke mně od Davida Klusáčka, mne zaujala natolik, že jsem se
ji pokusil ověřit. Vytvořil jsem proto jednak metadata s~časovými pozicemi všech
izolovaných řečových událostí na základě zarovnaného automatického přepisu, kde
jsem vynechal všechny fonémy \texttt{sil} a \texttt{sp}, a jednak sadu skriptů
pro manipulaci se soubory MFCC.

Celkový přínos pro úspěšnost rozpoznávání byl nulový (viz sekci~\ref{sec:evaluace}), ale aparát pro dekódování
a manipulaci souborů MFCC považuji za vítaný vedlejší produkt.

\section{Aktivní učení}

Aktivní učení spočívá ve vhodném výběru trénovacích dat, viz např. Cohn
1996\cite{cohn1996active}. V~mém případě trénovací sada postupně roste a je tedy
nabíledni techniky aktivního učení využít tak, aby se získávala co nejvhodnější
trénovací data.

Podnikl jsem experiment, ve kterém jsem slova s~nízkou {\em confidence
measure (c.m.)} (pod 0,3) červeně podtrhl přerušovanou čarou, jejíž sytost spojitě rostla
s~klesající c.m. Instruoval jsem pak uživatele aplikace, aby přednostně
přepisovali věty, které jsou opticky co nejčervenější. Bohužel přirozené puzení
uživatelů přepisovat nahrávku kompletně a lineárně od začátku způsobilo, že
přepisů, kde se tato instrukce dodržuje, je zcela mizivé množství.

Druhý experiment spočíval v~tom, že webová aplikace sama vybírala věty pro
přepis na základě toho, kolik obsahovala slov s~nízkou c.m. Uživatelé pak byli
instruováni, aby nahrávku jen poslouchali, a opravu vložili, až když se
přehrávání samo přeruší. Tento pokus skončil ještě palčivějším neúspěchem, neboť
změna v~chování aplikace byla pro uživatele natolik nepříjemná, že jsem je
raději navrátil do původního.

\section{Rozšíření trénovací množiny}
\label{sec:confident}

Skóre confidence measure se dá využít ještě jiným způsobem: lze vybrat všechny
úseky v~korpusu kromě testovací sady\footnote{K zamyšlení: je zde opravdu nutné
vynechat testovací data?}, kde automatický přepis uvádí vysokou míru
c.m. a přidat tyto úseky do trénovací množiny. Tento experiment jsem provedl
tak, že minimální délku úseku jsem stanovil na 1 sekundu, minimální počet
obsažených fonémů na 10 a minimální c.m. na 0,6. Práh 0,6 jsem určil namátkovou
kontrolou, která poukazovala na zanedbatelnou chybovost takových úseků. Celkem
tento výběr poskytl 99 hodin audia, tedy 10\% celého korpusu.
Chybovost rozpoznávání klesla zanedbatelně.

\section{Neuronové sítě}
\label{sec:deepspeech}

V~průběhu psaní této disertace se rozšířilo používání hlubokých neuronových sítí
snad ve všech oblastech strojového učení, viz např. LeCun
2015\cite{lecun2015deep}, Hinton 2012\cite{hinton2012deep}. Toto neminulo ani
rozpoznávání řeči, konceptuelně již dávno před tím, viz Morgan 1995\cite{morgan1995neural}. Gaußovské mixtury
přestaly být state of the art a systémy založené na hlubokých neuronových sítích
(DNN) skýtají mnohem větší úspěšnosti díky tomu, že lépe modelují fenomén fonémů
a umožňují i přímo modelovat grafémy na základě parametrizovaného zvuku, tedy
přeskočit vrstvu výslovnosti.

Nezisková organizace Mozilla vydala vlastní svobodný nástroj pro rozpoznávání
řeči DeepSpeech\cite{hannun2014deep} založený na
TensorFlow\cite{abadi2016tensorflow}.

V~době, kdy jsem s~DeepSpeech experimentoval, nebyla mi známa žádná implementace
na češtinu. DeepSpeech dovoluje vstup pouze ve znakové sadě písmen bez
diakritiky a několika málo interpunkčních znamének. Provedl jsem
tedy jednoduché kódování češtiny tak, že každé diakritické znaménko se vyjádří
jako apostrof před modifikovaným písmenem. Jediné dva případy, kdy jeden znak
může mít různá znaménka, jsou {\em é ě} a {\em ú ů}. Přisoudil jsem proto znaku
{\em ě} zápis \texttt{'j} a znaku {\em ů} zápis \texttt{'w}.

Klasická věta {\em příliš žluťoučký kůň úpěl ďábelské ódy} by se tedy zapsala
jako \texttt{p'r'ili's 'zlu'tou'ck'y k'w'n 'up'jl 'd'abelsk'e 'ody}. Je jasné,
že takové kódování by nebylo jednoznačně převoditelné na původní text v~obecném
případě, kdy se v~textu mohou vyskytovat apostrofy, a navíc by si neporadilo se
slovy s~jinými znaky, ale pro trénovací data pro akustické modelování češtiny
dostačuje. Věty, kde se vyskytují jiné znaky, z~trénovací sady vyřazuji. Případné
apriorní apostrofy mažu.

DeepSpeech trénuji na stejné sadě jako výchozí markovovský systém, tedy na
manuálních přepisech Karla Makoně. Jazykový model používám taktéž stejný, tedy trigramový, viz
sekci~\ref{sec:jazykovy-model} o jazykovém modelování.

DeepSpeech predikuje na úrovni písmen, takže v~některých případech umístil
apostrof před neočekávaný znak. Také způsob, kterým DeepSpeech používá jazykový
model, je svérázný. Dokud má akustický model důvěru ve svoji predikci,
k~jazykovému modelu se neuchyluje. A pokud se uchýlí, vinou programátorské chyby
výstup postrádá mezery.

Bohužel vinou přímého mapování z~parametrizovaného audia na grafémy přicházíme o
možnost zarovnání na úrovni fonémů, takže je nutno výstup nechat zarovnat
v~další iteraci, aby se umožnilo synchronní přehrávání ve webovém rozhraní.

Úspěšnost má DeepSpeech, jak jsem ho použil, znatelně nižší, než výchozí
markovovský model, a sice 51,76\% word error rate. Připisuji to jednak chybné aplikaci jazykového modelu a
jednak tomu, že DeepSpeech predikuje na úrovni písmen, takže velice často je
skoro celé slovo správně, až na jedno písmeno. Je možné, že 89 hodin trénovacích
dat je pro tento systém příliš málo, ačkoliv manuál ani diskuze na fóru tomu
nenasvědčují.

\section{Jazykový model}
\label{sec:jazykovy-model}

Jazykový model obecně je pravděpodobnostní rozdělení posloupností slov
v~jazyce.\cite{ponte1998language} V~kontextu rozpoznávání řeči je tandemovým
partnerem akustického modelu.\cite{jelinek1990self} Teprve kombinace akustického
a jazykového modelu určí výsledné slovo, které se na dané pozici rozpozná jako
nejpravděpodobnější.

Výběr jazykového modelu je omezen nástrojem pro rozpoznávání. Lze zvolit pouze
takový model, který nástroj dokáže využít. Všechny nástroje, které jsem použil,
podporují N-gramové jazykové modely: HVite bigramový, Julius až trigramový a
DeepSpeech taktéž trigramový.

Pro trénování jazykového modelu mám k dispozici čtyři druhy dat:
\begin{enumerate}
\item{Obecné české texty,}
\item{Makoňovy spisy,}
\item{manuální přepisy nahrávek,}
\item{automatické přepisy.}
\end{enumerate}

Každá z~těchto kategorií skýtá různé množství textu a různou věrnost
modelovanému materiálu. Nejvěrnější jsou samozřejmě manuální přepisy Makoňových
nahrávek, také je jich nejméně: přesně 712 388 slov v~okamžiku psaní tohoto
textu. Automatické přepisy, jejichž přínos pro jazykové modelování je nejasný,
představují 8 119 427 slov. Makoňovy spisy obsahují 3 328 720 slov. Obecné české
texty jsou nejdostupnější z~těchto komodit. Nejobsáhlejší dostupný korpus, který
jsem nalezl, je Mononews z WMT obsahující 1 019 497 060 slov.

Manuálním testováním jsem dospěl k~vahám $1 : 2000 : 7999 : 0$ pro korpusy ve
výše uvedeném pořadí. Aplikuji vyhlazování technikou
Knesser-Ney\cite{chen1999empirical}, jak je zabudována do nástroje pro tréning
jazykových modelů KenLM\cite{heafield2011kenlm}.

K~manuálním přepisům je třeba podotknout, že u nich dochází k~jednomu
nežádoucímu jevu. Přepisy se pořizují tak, aby byly maximálně věrné tomu, co je
vyřčeno. Proto se doslova... vlastně do hlásky přepisují i přebrepty a zadrhnutí.
Je otázkou, zda takové jevy chceme mít v~jazykovém modelu. Aniž bych se na ni
pokoušel poskytnout definitivní odpověď, můj přístup, jak se s~tímto vypořádat,
je, že instruuji uživatele, aby každé slovo, po kterém následuje přerušení toku
mluvy, doplnili třemi tečkami. Například ve větě {\em ,,To je ta relativnost
dobrého a zlého, tak kdybychom... to je tam jinak postaveno.``} patří tři tečky
za slovo {\em kdybychom}. Pokud se mluvčí zadrhne uprostřed slova nebo vysloví
něco, co není slovem, pokyn zní připojit k~takovému útvaru pomlčku. Příkladem
budiž věta {\em ,,To je první š- špatný pohled, chybný pohled na rodiče a na
předcházející generaci.``}. Zde patří pomlčka za vyslovené {\em š}, za kterým
teprve následuje vyslovené slovo {\em špatný}.

Toto značení umožňuje při stavbě jazykového modelu větu ukončit při setkání
s~takovým slovem nebo takové slovo přeskočit.

\section{Úspěšnost}
\label{sec:evaluace}

Poslední naměřená úspěšnost markovovského akustického modelu s~výše zmíněným
jazykovým modelem je 67,83\% word precision\footnote{počet správně určených slov
dělen počtem slov ve zlatém standardu} a 46,32\% word error rate.

Vzhledem k~tomu, že mi v~průběhu projektu rostla trénovací sada a testovací sadu
jsem určil fixně taktéž až v~průběhu projektu, nelze jednotlivá historická skóre přímo
porovnávat, musí se u každého experimentu pohlížet na to, jak změnil skóre
oproti bezprostředně předcházejícímu.

Tabulka~\ref{tab:asr-scores} uvádí seznam úspěšností jednotlivých experimentů.

\begin{table}[htpb]
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
experiment & \makecell{násobek\\ word\\ precision} & \makecell{násobek\\ word error\\ rate} \\
\hline
výchozí GMM model  & 1 & 1 \\
vysoké c.m. v~trénovací sadě (sekce~\ref{sec:confident}) & TODO & TODO \\
vlastní kepstrální normalizace (sekce~\ref{sec:mfcc-norm}) & 1,0007 & 0,9890 \\
DeepSpeech (sekce~\ref{sec:deepspeech}) & 0,7666 & 1,1422 \\
\hline
\end{tabular}
\caption{změny úspěšností jednotlivými experimenty}\label{tab:asr-scores}
\end{center}
\end{table}

Proč je úspěšnost tak nízká? V~roce 2016 publikovali Mizera et
al.\cite{mizera2016kaldi} sadu receptů na rozpoznávání řeči pro češtinu.
Uvádějí jako state of the art techniky GMM-HMM a DNN-HMM a word error rate pro
jednotlivé recepty mezi 8,49 a 48,47 podle povahy dat. Úspěšnost na korpusu
Karla Makoně v~tomto porovnání není vyloženě nízká. Zásadním faktorem je jistě
kolísavá akustická kvalita nahrávek. Svoji roli zde jistě hraje i použití jednak
zastaralého systému HTK a jednak pro češtinu jen ledabyle přizpůsobeného
systému DeepSpeech.
