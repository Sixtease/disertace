\chapter{Automatický přepis}
\label{kap:asr}

% - množina fonémů
% - vektorový formát
% - HMM X CNN
% - HTK X Kaldi X sphinx X Bourlard X TensorFlow
% - Monofonémy X trifonémy
% - mixtury
%   - individuální
%   - globální
%   - na monofonémech vs. trifonémech

Koncept celého projektu se zakládá na~přítomnosti počátečního přepisu a jeho
následném zdokonalování. Pro získání počátečního přepisu bylo nutné sestavit
systém pro automatický přepis, z~historických důvodů častěji označovaný jako
rozpoznávání řeči. Rozpoznávání češtiny se věnovali mnozí přede mnou,
například Ircing et al. 2001\cite{ircing2001large}, Psutka et al.
2005\cite{psutka2005automatic}, či Byrne et al. 1999\cite{byrne1999large}.
V následujících odstavcích popíšu tvorbu rozpoznávače řeči pro korpus Karla
Makoně.

Zjednodušený řetězec vedoucí od~zvukových dat k~jejich přepisu v~našem případě
vypadá takto:\begin{enumerate}
\item{sběr trénovacích dat,}
\item{stavba akustického modelu,}
\item{stavba jazykového modelu,}
\item{automatické rozpoznávání.}
\end{enumerate}

První trénovací sadu jsem pořídil svépomocí přepisem asi 15 minut nahrávky
\texttt{85-05A}.

V~průběhu práce jsem sestavil dva zcela odlišné akustické modely: Jeden založený
na skrytých markovovských modelech a jeden založený na neuronových sítích.
Hlavním důvodem bylo to, že když jsem začínal, nebyly ještě hluboké neuronové
sítě tak rozšířené. Jsou ale i dvě další výhody, které použití markovovských
modelů opodstatňují: 1) Nepotřebují tolik trénovacích dat, takže se více hodí do
začátku, kde je přepsaná množina malá, a 2) umožňují získat přesné zarovnání
slov a hlásek na časové pozice ve zvukovém záznamu. Dosud neznám žádný nástroj
založený na hlubokých neuronových sítích, který by toto poskytoval.

Nejdříve popíšu výstavbu markovovského modelu a poté od
sekce~\ref{sec:deepspeech} se budu věnovat modelu založenému na neuronových
sítích.

\section{Základní tvorba akustického modelu}

Do~užšího výběru potenciálních platforem tvorby akustického modelu jsem zařadil
starší systém \textit{HTK}\footnote{HMM ToolKit; HMM = Hidden Markov Model}\cite{young2002htk} a
modernější \textit{Kaldi}\cite{povey2011kaldi}. HTK pomyslný konkurz nakonec vyhrál díky zkušenostem
mého konzultanta Mgr. Nina Peterka, Ph.D. s~tímto systémem, z~nichž jsem mohl
čerpat.

Akustický model jsem trénoval výhradně z~vlastních dat.
% Obětoval jsem tedy
% potenciální přínos většího množství trénovacích dat a upřednostnil trénování
% přímo na~konkrétního mluvčího.
%TODO: od kdy se vyplatí dělat model na konkrétního mluvčího?

Tvorba akustického modelu probíhala podle návodu v~manuálu k~HTK, \textit{HTK
Book}. V~hrubých rysech probíhá takto:

\begin{enumerate}

\item{Vytvoření počátečních modelů}

Modeluje se skrytými markovovskými řetězci. Všechny fonémy se inicializují jako
shodné. Každý foném je reprezentován pěti stavy (vstupním, výstupním a třemi
vnitřními). Přechodové pravděpodobnosti se nastaví tak, aby byly možné jen
kýžené přechody, to jest ze~vstupního do~druhého a z~každého z~vnitřních stavů
do~sebe samého nebo do~následujícího. Konkrétní pravděpodobnosti nejsou
podstatné, ale použil jsem 60\% pro setrvání a 40\% pro postup ve~druhém a
třetím stavu a 70\% pro setrvání a 30\% pro postup ze~čtvrtého do~výstupního.
Střed a variance jsou určeny identicky podle globálních hodnot.

Kromě vlastních fonémů (viz níže sekci~\ref{sec:ac:fonetika}) přidám ještě foném
pro~ticho (\texttt{sil}).

Pro kódování používám formát MFCC s~první a druhou derivací, nultým koeficientem
a kepstrální normalizací (\texttt{MFCC\_0\_D\_A\_Z} v~notaci HTK).

Následují dvě iterace tréninku Baum-Welchovým algoritmem\cite{welch2003hidden}.

\item{Přidání modelu pro krátkou pauzu}

Z~modelu pro ticho se odvodí model pro krátkou pauzu tak, že se povolí přechod
rovnou z~druhého do~čtvrtého stavu a zpět, aby byl model robustnější a mohl
modelovat pauzu mezi slovy, která je nezřídka nulová.

Trénuje se opět dvěma iteracemi BW-algoritmu.

\item{Nucené zarovnání a odvržení zmetkových vzorků}

Pomocí Viterbiho algoritmu\cite{forney1973viterbi} se provede tzv.
\textit{forced alignment}, tzn. nucené zarovnání na~úrovni fonémů. Jinými slovy
určí se přesný čas, kde začíná a končí který foném. Při tom se určí hranice, pod
kterou když klesne \textit{likelihood} daného přepisu na~základě odpovídající
nahrávky, tato se z~trénovacích dat odstraní jako pravěpodobně vadná. Následují
další dvě iterace BW-algoritmu.

\item{Přepočítání variance}

Variance modelů byla určena podle původní trénovací sady. Nyní jsme z~ní
vyřadili některé vzorky, proto proběhne její přepočtení, opět následované dvěma
trénovacími iteracemi.

\item{Přechod k~trifonémům}
\label{item:htktrain:triphones}

Z~nuceného zarovnání máme přepis obohacený o~konkrétní fonetické realizace. Z~té
se nyní snadno vytvoří přepis trifonémový tak, že ke každému fonému přidáme
jeho levý a pravý kontext, pokud nejsou na~začátku nebo na~konci věty.

Je-li fonémů 45, pak trifonémů je až $45^3 = 91125$. Ne všechny se v~trénovacích
datech objeví. V~praxi jich mám kolem 14 tisíc. Pokud by každý trifoném měl
vlastní separátní model, došlo by k~opačnému problému než v~případě monofonémů,
totiž že by celkový model měl příliš mnoho parametrů. Přechodové matice mohou
všechny trifonémy odvozené od jednoho monofonému sdílet. Avšak které trifonémy
mají sdílet varianci a které mají mít vlastní, je třeba rozhodnout opatrněji.

Pro určení, které modely je vhodné sloučit, používám rozhodovací stromy.
Na~základě předem definovaných kritérií se u~každého emitujícího stavu každé
skupiny trifonémů provede rozdělení na~dva shluky, což umožní zvýšení
\textit{log likelihood} dat. Vybere se kritérium, které ji zvýší nejvíce a
postup se opakuje, dokud zvýšení neklesne pod~danou hranici. Takto získané
shluky se pak sloučí do jednoho logického trifonému.

\item{Štěpení mixtur}

Posledním krokem ve~zvětšování komplexity modelu je štěpení tzv.~\textit{mixtur}
(z~angl. \textit{mixtures}). Spočívá v~tom, že se přesněji modelují variantní
realizace jednotlivých fonémů. Daný foném v~jednom stavu HMM pak není modelován jednou gaußovskou
distribucí, nýbrž složením několika. Každá má svůj střed, svoji varianci a svoji
váhu, jejichž celkový součet musí být roven jedné.

Štěpí se vnitřní stavové modely jednotlivých fonémů. Optimální počet
mixtur je tedy potřeba zjistit pro trojnásobek počtu použitých trifonémů. To
jsou řádově tisíce až desítky tisíc. V~okamžiku psaní tohoto textu používám 8444
reálných trifonémů, 13746, počítám-li i ty virtuální. To znamená přes dvacet pět
tisíc distribucí, u~nichž je potřeba určit optimální počet mixtur.

Aby byl úkol aspoň aproximací dosažitelný, je třeba hledat efektivněji než
prohledáváním celého prostoru hrubou silou. První pomocí zde je, že modely jsou
na sobě více méně nezávislé: Nalezneme-li optimální počet mixtur pro jeden
z~nich, nemělo by to ovlivnit optimální počet mixtur u~jiného.

Rozštěpení u~jednoho modelu proběhne tak, že se mixtura s~největší vahou
rozštěpí na dvě totožné, jen jedna dostane malinko větší váhu než druhá, aby se
při trénování mohly rozejít. To se provede u~všech vnitřích stavů všech
logických fonémů, t.j. u~všech markovovských modelů. Provedou se čtyři trénovací
iterace a úspěšnost se vyhodnotí na~sadě heldout.

Pokud u~některé mixtury klesne její váha pod~daný práh, vymaže se, čímž se
zamezí zbytečnému nárůstu parametrů a není proto potřeba zkoušet štěpit
jednotlivé modely samostatně. Arci, štěpením modelů jednoho po druhém jsem nikdy nedosáhl lepšího
výsledku, než štěpením všech modelů najednou.

Závislost úspěšnosti na~počtu mixtur není monotónní, proto ve~štěpení pokračuji,
i když někdy úspěšnost klesne. Konkrétně zastavím štěpení, pokud úspěšnost
klesne o~více než 30\% oproti nejvyšší dosažené nebo pokud klesne více než
třikrát za~sebou, ale nikdy když je mixtur méně než 16.

%Pokud je foném gaußiánem modelován dobře, rozdělení na dvě mixtury
%nijak nepomůže. Navíc pokud rozdělíme dostribuci příliš, dojde snadno
%k~přetrénování. Je proto potřeba nalézt optimální počet mixtur pro každý
%jednotlivý trifoném.

\end{enumerate}

\section{Segmentace}

Zpravidla jeden zvukový soubor odpovídá jednomu přetočení magnetofonové pásky,
obvyklá délka je tedy 45 až 120 minut. Takto dlouhé úseky nelze použít ani jako
trénovací příklady ani jako cíl automatického rozpoznávání.

Sofistikovanější segmentaci popisuji v~sekci~\ref{sec:segmenty}. Pro účely
vývoje iniciálního systému automatického přepisu jsem však použil jednodušší
metodu:

Celá aplikace je pojata jako nástroj pro~zdokonalování automatického přepisu,
takže vychází z~předpokladu, že nějaký přepis již existuje. Vycházeje z~téhož
předpokladu při~segmentaci, realizoval jsem ji tak, že zvukový soubor se rozdělí
na~úseky odpovídající jednotlivým větám v~přepisu, ne však delší než patnáct
sekund. Pokud by věta byla delší, rozdělí se u nejbližšího slova
před~patnáctisekundovou hranicí.

V~případě, že pro daný záznam zatím žádný přepis neexistuje, rozdělí se naivně
na~patnáctisekundové úseky.

\section{Fonetika}
\label{sec:ac:fonetika}

\subsection{Fonetický přepis}

Trénovací data pro akustické modelování pomocí HTK mají formu párů
parametrizovaných zvukových souborů (v~mém případě MFCC) a textových souborů,
obsahujících fonetický přepis. Ten se může získat různými způsoby. Lze ručně
anotovat data do~fonetického i běžného přepisu, což je zdlouhavé a náročné. Běžně
se trénovací přepisy do fonetických převádějí automaticky. U jazyků
s~nepravidelnou výslovností, jako je angličtina, je často nejlepší použít
robustní výslovnostní slovník a v~případě jeho nedostatečnosti se uchýlit
k~pravidlové výslovnosti, popř. anotovat mimoslovníková slova ručně.

Čeština skýtá se svojí téměř deterministickou a navíc relativně jednoduchou
fonetikou možnost používat primárně pravidlový přepis. Výjimky pak lze ošetřit
slovníkem. Vzhledem k~tomu, že slovní zásoba Karla Makoně je svérázná a
netypická, vydal jsem se právě touto cestou, neboť i kvalitní robustní slovník
by zde byl nedostatečný a svou obsáhlostí zbytečný.

Pro podrobnější popis získávání fonetického přepisu viz sekci~\ref{ssec:porizeni-fonetickeho-prepisu}.

\subsection{Fonémy}

% TODO cite

Používám základní fonémy českého jazyka\cite{palkova1992fonetika}
reprezentované pomocí PACal\cite{nouza1997phonetic}. Kromě základních fonémů
používám dvojhlásky, ticho a krátkou pauzu. Ráz (glotální plozivu) nevyznačuji,
jakož ani neřečové události.
V~tabulce~\ref{tab:phones} jsou fonémy uvedeny.

\begin{table}[htpb]
\fontspec{DoulosSIL}
\begin{center}
\begin{tabular}{|l|l|l||l|l|l|}
\hline
IPA & PACal & grafém & IPA & PACal & grafém \\
\hline
a  & a   & a      &     ɱ  & mg  & tra\underline{m}vaj \\
aː & aa  & á      &     n  & n   & \underline{n}e \\
aʊ̯ & aw  & au     &     ŋ  & ng  & ta\underline{n}k \\
b  & b   & b      &     ɲ  & nj  & \v{n} \\
t͡s & c   & c      &     o  & o   & o \\
t͡ʃ & ch  & č      &     oː & oo  & ó \\
d  & d   & d      &     oʊ̯ & ow  & ou \\
ɟ  & dj  & \v{d}  &     p  & p   & p \\
d͡z & dz  & dz     &     r  & r   & r \\
d͡ʒ & dzh & dž     &     r̝̊  & rsh & t\underline{\v{r}}i \\
ɛ  & e   & e      &     r̝  & rzh & \underline{\v{r}}íz \\
ɛː & ee  & é      &     s  & s   & s \\
eʊ̯ & ew  & eu     &     ʃ  & sh  & š \\
f  & f   & f      &     t  & t   & t \\
g  & g   & g      &     c  & tj  & \v{t} \\
ɦ  & h   & h      &     ʊ  & u   & u \\
i  & i   & i      &     uː & uu  & ú, \r{u} \\
iː & ii  & í      &     v  & v   & v \\
j  & j   & j      &     x  & x   & ch \\
k  & k   & k      &     z  & z   & z \\
l  & l   & l      &     ʒ  & zh  & ž \\
m  & m   & \underline{m}ák
                  &        & sil & \\
   &     &        &        & sp  & \\
\hline
\end{tabular}
\caption{použité fonémy: IPA, PACal a nejčastější odpovídající
grafém}\label{tab:phones}
\end{center}
\end{table}
\normalfont

V~závislosti na~množství trénovacích dat bylo vhodné nahradit některé fonémy
častějšími podobnými. V~tabulce~\ref{tab:phonesed} jsou záměny vyčísleny.
\begin{table}[htpb]
\fontspec{DoulosSIL}
\begin{center}
\begin{tabular}{|r|l|l||l|l|}
\hline
&
\multicolumn{2}{|c||}{před záměnou} &
\multicolumn{2}{|c|}{po záměně} \\
\hline
& IPA & PACal & IPA & PACal \\
\hline
    & ɱ  & mg & m & m \\
    & aʊ̯ & aw & a ʊ & a u \\
    & oː & oo & o & o \\
\** & d͡z & dz & t͡s & c \\
    & d͡ʒ & dzh & t͡ʃ & ch \\
\** & eʊ̯ & ew & ɛ ʊ & e u \\
\hline
\end{tabular}
\caption{použité záměny fonémů; hvězdičkou jsou vyznačeny záměny použité ještě
v~době psaní textu}\label{tab:phonesed}
\end{center}
\end{table}
\normalfont

\section{Rozdělení dat}

Pro natrénování modelu strojovým učením je potřeba trénovacích dat a pro
vyhodnocení jeho úspěšnosti dat testovacích, která ve~fázi trénování nesmí být
algoritmem spatřena. Při trénování samotném se pak mnohdy používá vyhrazených,
tzv.~\textit{heldout} dat\footnote{často zaměňovaných s~vývojovou testovací sadou
označovanou běžně jako \textit{dev} / \textit{dtest}} pro průběžné měření úspěšnosti. V~případě trénování
akustického modelu s~použitím HTK je tomu nejinak. Heldout data jsou používána
pro zjištění optimálního počtu mixtur modelů jednotlivých fonémů, a testovací
pro závěrečné vyhodnocení.

Anotovaná data mi přibývala velice pozvolna a začínal jsem s~několika minutami,
ovšem přírůstky byly časté. Nemohl jsem si tedy dovolit udělat od~začátku pevnou
testovací sadu, kterou bych používal po~celou dobu provádění experimentů. Místo
toho jsem s~každou novou dávkou anotovaných dat celou sadu rozdělil podle vět
v~poměru 18:1:1 do trénovací, heldout a testovací sady. Tak jsem měl neustále
vyvážený poměr jednotlivých datových sad. Zřejmou velkou nevýhodou bylo, že
nešlo spolehlivě porovnávat výsledky jednotlivých experimentů vzhledem
k~variabilní testovací sadě.

Až když jsem měl několik desítek hodin anotovaných dat, vyhradil jsem si fixní
testovací sadu. Běžně se testovací sada vybere jako náhodná podmnožina vzorků
z~trénovací sady tak, aby měla kýženou velikost. V~mém případě vzorků zvíci
hodinových nahrávek jsem sadu určil manuálně jako úsek druhé až jedenácté minuty
(tedy deset minut minutu po~začátku) v~pěti nahrávkách,
\begin{enumerate}
\item{jedné kazety z~roku 1976,}
\item{jedné z~roku 1982,}
\item{jedné z~roku 1986,}
\item{jedné z~roku 1990 a}
\item{jednoho nedatovaného kotouče.}
\end{enumerate}

Sadu heldout nyní vybírám jako každou čtyřicátou větu. Z~každé dvacáté jsem
snížil na~polovic nejen abych neplýtval trénovacími daty, nýbrž také protože
vyhodnocování mixtur zabírá při trénování zdaleka nejvíce času, a ten je přímo
úměrný velikosti sady heldout.

\section{Spojování trifonémů}

Pro slučování modelů jednotlivých trifonémů, jak zmiňuje
bod~\ref{item:htktrain:triphones} seznamu kroků trénování pomocí~HTK, je
zapotřebí rozhodovacích stromů. Pro jejich tvorbu je potřeba ručně vytvořit
otázky, na základě nichž bude algoritmus dělit fonémy do shluků. K~tvorbě
otázek můžeme použít lingvisticky motivovanou kategorizaci v~naději, že aspoň
některé lingvistikou definované kategorie budou tvořit konzistentní shluky
z~pohledu trénovacích dat. Pro tvorbu otázek jsem vycházel z~předlohy pro
angličtinu, jak je v HTK Book a z~kategorizace českých hlásek na Wikipedii ({\em
https://cs.wikipedia.org/wiki/Fonologie~češtiny}).
% TODO otázky do apendixu

\section{Experiment s kepstrální normalizací}
\label{sec:mfcc-norm}

Kepstrální normalizace je standardní technikou pro kompenzaci různorodých
akustických podmínek v~rámci trénovacích a testovacích dat, viz Viikki a Laurila
1998\cite{viikki1998cepstral}. Princip této techniky spočívá v~tom, že se ode
všech melfrekvenčních kepstrálních koeficientů odečte jejich průměr z~akusticky
konzistentního úseku. Já toto poněkud hrubiánsky činím na celých nahrávkách,
které nejsou vždy akusticky konzistentní, ale často ano, a nalezení akusticky
podobných množin je jedním z~mých plánů pro budoucí práci.\footnote{Tato úloha
je již vyřešena a popsána v~sekci~\ref{sec:akustika:metrika} a následující.}

Nabízí se však otázka, zda má smysl odečítat průměr z~celé nahrávky, nebo by to
mělo být jen z~řečových událostí, tedy s~vynechaným tichem (šumem, hluky atd.)
Tato idea, přišedší ke mně od Davida Klusáčka, mne zaujala natolik, že jsem se
ji pokusil ověřit. Vytvořil jsem proto jednak metadata s~časovými pozicemi všech
izolovaných řečových událostí na základě zarovnaného automatického přepisu, a jednak sadu skriptů
pro manipulaci se soubory MFCC.

Ke každému souboru MFCC jsem vytvořil kopii, ze které
jsem vynechal všechny fonémy \texttt{sil} a \texttt{sp}. Průměry kepstrálních
koeficientů jsem pak spočetl na těchto kopiích a odečetl je od hodnot
v~originálech. Trénování i testování jsem pak prováděl na takto upravených
souborech místo standardní normalizace, jak ji poskytuje systém HTK.

Celkový přínos pro úspěšnost rozpoznávání byl nulový, ale aparát pro dekódování
a manipulaci souborů MFCC považuji za vítaný vedlejší produkt.

\section{Aktivní učení}

Aktivní učení spočívá ve vhodném výběru trénovacích dat, viz např. Cohn
1996\cite{cohn1996active}. V~mém případě trénovací sada postupně roste a je tedy
nabíledni techniky aktivního učení využít tak, aby se získávala co nejvhodnější
trénovací data.

Podnikl jsem experiment, ve kterém jsem ve webovém rozhraní ke sběru trénovacích
dat (viz kapitolu~\ref{kap:webove-rozhrani}) slova s~nízkou {\em confidence
measure (c.m.)} (pod 0,3) červeně podtrhl přerušovanou čarou, jejíž sytost spojitě rostla
s~klesající c.m. Instruoval jsem pak uživatele aplikace, aby přednostně
přepisovali věty, které jsou opticky co nejčervenější. Bohužel přirozené puzení
uživatelů přepisovat nahrávku kompletně a lineárně od začátku způsobilo, že
přepisů, kde se tato instrukce dodržuje, je zcela mizivé množství.

Druhý experiment spočíval v~tom, že webová aplikace sama vybírala věty pro
přepis na základě toho, kolik obsahovala slov s~nízkou c.m. Uživatelé pak byli
instruováni, aby nahrávku jen poslouchali, a opravu vložili, až když se
přehrávání samo přeruší. Tento pokus skončil ještě palčivějším neúspěchem, neboť
změna v~chování aplikace byla pro uživatele natolik nepříjemná, že jsem je
raději navrátil do původního.

\section{Rozšíření trénovací množiny}
\label{sec:confident}

Skóre confidence measure se dá využít ještě jiným způsobem: lze vybrat všechny
úseky v~korpusu kromě testovací sady\footnote{K zamyšlení: je zde opravdu nutné
vynechat testovací data?}, kde automatický přepis uvádí vysokou míru
c.m. a přidat tyto úseky do trénovací množiny. Tento experiment jsem provedl
tak, že minimální délku úseku jsem stanovil na 1 sekundu, minimální počet
obsažených fonémů na 10 a minimální c.m. na 0,6. Práh 0,6 jsem určil namátkovou
kontrolou, která poukazovala na zanedbatelnou chybovost takových úseků. Celkem
tento výběr poskytl 99 hodin audia, tedy 10\% celého korpusu.
Chybovost rozpoznávání se statisticky významně nezměnila, za to doba trénování
se zvýšila citelně.

\section{Neuronové sítě}
\label{sec:deepspeech}

V~průběhu psaní této disertace se rozšířilo používání hlubokých neuronových sítí
snad ve všech oblastech strojového učení, viz např. LeCun
2015\cite{lecun2015deep}, Hinton 2012\cite{hinton2012deep}. Toto neminulo ani
rozpoznávání řeči, konceptuelně již dávno před tím, viz Morgan 1995\cite{morgan1995neural}. Gaußovské mixtury
přestaly být state of the art a systémy založené na hlubokých neuronových sítích
(DNN) skýtají mnohem větší úspěšnosti díky tomu, že lépe modelují fenomén fonémů
a umožňují i přímo modelovat grafémy na základě parametrizovaného zvuku, tedy
přeskočit vrstvu výslovnosti.

Nezisková organizace Mozilla vydala vlastní svobodný nástroj pro rozpoznávání
řeči DeepSpeech\cite{hannun2014deep} založený na
TensorFlow\cite{abadi2016tensorflow}.

Akustický model jsem natrénoval dvojí: Jednak čistě na manuálních přepisech
Makoňových nahrávek (v~době psaní 100 hodin) a jednak na agregované sadě popsané
v~sekci~\ref{sec:csasr:results}.

Model natrénovaný jen na Makoňových nahrávkách zkonvergoval po osmi epochách a
dosáhl word error rate 19,2\% na testovací sadě. Druhý model jsem vytvořil tak,
že jsem trénoval nejdříve na agregované trénovací sadě s~použitím Makoňovy
heldout sady pro validaci. Tato část zkonvergovala po 16 epochách a dosáhla WER
27,3\%. Následně jsem pokračoval v~tréninku na Makoňových nahrávkách. Tato část
zkonvergovala po dvou epochách a konečné skóre bylo 23,5\% WER.

Na testovací sadě má tedy vyšší úspěšnost model trénovaný jen na 100h Makoňových
nahrávek, předče model trénovaný na 1500 hodinách. Onen druhý robustnější model
má však mnohem lepší výsledky na velice poškozených nahrávkách, které jsem
v~době výběru testovací sady ještě neměl k~dispozici, any byly digitalizovány
mnohem později. Jedná se hlavně o nahrávky pořizované při nízké rychlosti
převíjení pásky, zmiňované jednak v~sekci~\ref{sec:akustika:kompenzace} a jednak
v~sekcích~\ref{sec:data:rec} a \ref{sec:data:digitisation}.

Na kraťoučkém minutovém úseku jedné z~nejpoškozenějších nahrávek, který jsem
přepsal, má ryze makoňovský model WER 94,1\%, zatímco robustní model má WER
75,8\%. Porovnání na větším, asi pětiminutovém úseku je uvedeno
v~sekci~\ref{sec:akustika:vyhodnoceni}.

Bohužel vinou přímého mapování z~parametrizovaného audia na grafémy přicházíme o
možnost zarovnání na úrovni fonémů, takže je nutno výstup nechat zarovnat
v~další iteraci, aby se umožnilo synchronní přehrávání ve webovém rozhraní.

\section{Jazykový model}
\label{sec:jazykovy-model}

Jazykový model obecně je pravděpodobnostní rozdělení posloupností slov
v~přirozeném jazyce.\cite{ponte1998language} V~kontextu rozpoznávání řeči je tandemovým
partnerem akustického modelu.\cite{jelinek1990self} Teprve kombinace akustického
a jazykového modelu určí výsledné slovo, které se na dané pozici rozpozná jako
nejpravděpodobnější.

Výběr jazykového modelu je omezen nástrojem pro rozpoznávání. Lze zvolit pouze
takový model, který nástroj dokáže využít. Všechny nástroje, které jsem použil,
podporují N-gramové jazykové modely: HVite bigramový, Julius až trigramový a
DeepSpeech libovolného řádu.

Pro trénování jazykového modelu mám k dispozici čtyři druhy dat:
\begin{enumerate}
\item{Obecné české texty,}
\item{Makoňovy spisy,}
\item{manuální přepisy nahrávek,}
\item{automatické přepisy.}
\end{enumerate}

Každá z~těchto kategorií skýtá různé množství textu a různou věrnost
modelovanému materiálu. Nejvěrnější jsou samozřejmě manuální přepisy Makoňových
nahrávek, také je jich nejméně: přesně 715 285 slov v~okamžiku psaní tohoto
textu. Automatické přepisy, jejichž přínos pro jazykové modelování je nejasný,
představují 6 795 325 slov. Makoňovy spisy obsahují 3 328 720 slov. Obecné české
texty jsou nejdostupnější z~těchto komodit. Nejobsáhlejší dostupný korpus, který
jsem nalezl, je Mononews z WMT\cite{wmt19} obsahující 1 019 497 060 slov.

Manuálním testováním jsem dospěl k~vahám $1 : 2000 : 7999 : 0$ pro korpusy ve
výše uvedeném pořadí. Aplikuji vyhlazování technikou
Knesser-Ney\cite{chen1999empirical}, jak je zabudována do nástroje pro tréning
jazykových modelů KenLM\cite{heafield2011kenlm}.

K~manuálním přepisům je třeba podotknout, že u nich dochází k~jednomu
nežádoucímu jevu. Přepisy se pořizují tak, aby byly maximálně věrné tomu, co je
vyřčeno. Proto se doslova... vlastně do hlásky přepisují i přebrepty a zadrhnutí.
Je otázkou, zda takové jevy chceme mít v~jazykovém modelu. Aniž bych se na ni
pokoušel poskytnout definitivní odpověď, můj přístup, jak se s~tímto vypořádat,
je, že instruuji uživatele, aby každé slovo, po kterém následuje přerušení toku
mluvy, doplnili třemi tečkami. Například ve větě {\em ,,To je ta relativnost
dobrého a zlého, tak kdybychom... to je tam jinak postaveno.``} patří tři tečky
za slovo {\em kdybychom}. Pokud se mluvčí zadrhne uprostřed slova nebo vysloví
něco, co není slovem, pokyn zní připojit k~takovému útvaru pomlčku. Příkladem
budiž věta {\em ,,To je první š- špatný pohled, chybný pohled na rodiče a na
předcházející generaci.``}. Zde patří pomlčka za vyslovené {\em š}, za kterým
teprve následuje vyslovené slovo {\em špatný}.

Toto značení umožňuje při stavbě jazykového modelu větu ukončit při setkání
s~takovým slovem nebo takové slovo přeskočit.

\section{Úspěšnost}
\label{sec:evaluace}

Poslední naměřená word error rate markovovského akustického modelu s~výše zmíněným
jazykovým modelem je 46,3\%.

Vzhledem k~tomu, že mi v~průběhu projektu rostla trénovací sada, jsem testovací sadu
určil fixně taktéž až v~průběhu projektu. Výrazně v~ní chybí přepisy těch
nejméně srozumitelných nahrávek, které byly digitalizovány až po provedení
většiny experimentů, a navíc k~nim pořizovat ruční přepisy je velice nesnadné.

Tabulka~\ref{tab:asr-scores} uvádí nejdůležitější milníky ve word error rate. Je
s~podivem, že model dotrénovaný na Makoňových nahrávkách má na obecné testovací
množině větší úspěšnost (v~tabulce tučně) než výchozí model trénovaný na všech datech, jehož
úspěšnost je uvedená v~tabulce~\ref{tab:csasr:results}. Dalo by se čekat, že
když se po konvergenci na obecné trénovací množině aplikují ještě
další trénovací epochy na jiných specifických datech, měl by výkon stoupnout na
oněch specifických datech a poklesnout na datech obecných. Příčinu tohoto jevu
jsem dosud neměl příležitost prozkoumat.

\begin{table}[htpb]
\begin{center}
\begin{tabular}{|l|l|l|l|}
\hline
model & GMM & \makecell{ DNN trénovaný\\ na Makoňovi } & \makecell{ DNN trénovaný\\ na různých sadách } \\
\hline
\makecell{standardní testovací\\ množina (50min)} & 46,3\% & 19,2\% & 23,5\% \\ \hline
\makecell{5 minut\\ přebuzených záznamů} & & 45.0\% & 34,8\% \\ \hline
\makecell{ 5 minut\\ záznamů pořízených\\ nízkou rychlostí } & & 68,5\% & 42,1\% \\ \hline
\makecell{ 1 minuta obzvláště\\ nesrozumitelného záznamu } & & 94,1\% & 75,9\% \\ \hline
\makecell{agregovaná testovací\\ sada z~různých dat} & & 77,3\% & \textbf{25,3\%} \\ \hline
\end{tabular}
\caption{Chybovosti tří důležitých modelů na různých testovacích sadách}\label{tab:asr-scores}
\end{center}
\end{table}

Je úspěšnost nízká nebo vysoká? V~roce 2016 publikovali Mizera et
al.\cite{mizera2016kaldi} sadu receptů na rozpoznávání řeči pro češtinu.
Uvádějí jako state of the art techniky GMM-HMM a DNN-HMM a word error rate pro
jednotlivé recepty mezi 8,49 a 48,47 podle povahy dat. Úspěšnost na korpusu
Karla Makoně v~tomto porovnání tedy nijak nepřekvapuje, obzvláště s~přihlédnutím
k~velké akustické variabilitě materiálu.
