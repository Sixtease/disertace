\chapter{Automatický přepis}
\label{kap:asr}

% - množina fonémů
% - vektorový formát
% - HMM X CNN
% - HTK X Kaldi X sphinx X Bourlard X TensorFlow
% - Monofonémy X trifonémy
% - mixtury
%   - individuální
%   - globální
%   - na monofonémech vs. trifonémech



Koncept celého projektu se zakládá na~přítomnosti počátečního přepisu a jeho
následném zdokonalování.
Je tedy nutné opatřit způsob, jak korpus strojově převést do textové podoby. Tím
se dostáváme do oblasti z~historických důvodů zvané \textit{automatické
rozpoznávání řeči}, anglicky \textit{automated speech recognition}, zkracované
jako \textit{ASR}, ačkoliv z povahy věci by přesnějším výrazem byl
\textit{automatický přepis}.

Automatický přepis lze chápat jako úlohu transformace signálu nebo jako
rozpoznávání vzorců v~datech. Algoritmus takových úloh je obvykle velice
složitý, neboť variabilita vstupních dat je značná a také zadání je inherentně
vágní: mnohdy je i pro člověka obtížné rozeznat, jakou hlásku nebo jaké slovo
určitý zvuk představuje.

Řešení problému, jak systému předat potřebnou znalost mapování vstupních dat na
kýžený výstup, se řeší kombinací dvou přístupů: přímým zakomponováním lidské
expertizy a strojovým učením z~dat. Pojem strojové učení vznikl už v~roce
1959\cite{samuel1959some} a obor se od té doby rozvíjí a získává na popularitě.
Už legenda strojového zpracování přirozeného jazyka kladenský rodák Bedřich
Jelínek, lépe známý pod svým poangličtěným jménem Frederick Jelinek, proslul
svým výrokem, že kdykoliv vyhodí lingvistu, zvýší se mu úspěšnost systému.

Ve strojovém učení pracujeme s~pojmy \textit{trénovací data} a \textit{testovací
data}. V~obou případech se jedná o správně spárovaná vstupní a výstupní data.
V~případě ASR tedy jde o páry záznamů mluveného slova a odpovídajících přepisů.
Trénovací data jsou ta, která mám systém k~dispozici, aby z~nich odvodil znalost
potřebnou pro danou úlohu, tedy v~našem případě pro převod zvuku do textu.
Testovací data jsou potom ta, na nichž se vyhodnocuje úspěšnost systému.

Toto vychází z~předpokladu, že v~trénovacích datech je zobecnitelná informace,
která platí i o testovacích datech. Také se vychází z~předpokladu, že testovací
data jsou od trénovacích striktně oddělena, neboť jedině tak lze na základě
výsledku testování vyvozovat relevanci i pro další, neznámá data.

V~mém případě je úloha specifická tím, že se nesnažím vyvinout systém na
univerzální predikci neznámých dat: Jedná se mi o přepis daného korpusu, který
mám celý k dispozici. Karel Makoň je po smrti, takže dalších nahrávek se od něho
nenadějeme. Testovací sada oddělená od trénovací je však podstatná pro
vyhodnocení, ze kterého se dá soudit o výkonu na částech korpusu, pro který
chybí ruční přepis.

Výhoda strojového učení oproti ručním pravidlům je zřejmá: v~datech je informace
uložena objektivně, pravdivě. Oproti tomu v~ručně psaných pravidlech je zanesen
lidský faktor, který s~sebou nese předpojatost, omylnost a nepřesnost. Strojový
čas je navíc mnohdy dostupnější než lidský.

Nevýhodou strojového učení je, že je k~němu zapotřebí trénovacích dat, a to čím
více, tím lépe, aneb ,,there is no data like more data`` (Robert Mercer, 1985). Je
známo, že neuronová síť i hloubky 1 je s~dostatečným počtem neuronů schopna
modelovat jakoukoliv spojitou funkci s~omezeným definičním oborem (Csáji
2001)\cite{csaji2001approximation}. Kdybychom tedy měli neomezeně mnoho
kvalitních trénovacích dat a výpočetní kapacity, nebylo by důvodu aplikovat
lidskou expertizu.

Jelikož jsou však zdroje omezené, kombinují systémy typicky oba zdroje
expertizy: lidskou odbornost a strojové učení, přičemž historicky
s~dokonalejšími počítači a větším množstvím dat v~systémech ubývá jednoho a
přibývá druhého.

\section{Vybrané milníky v~rozpoznávání řeči}

První experimenty v~sedmdesátých letech porovnávaly vstupní zvukový záznam
s~množinou předloh a výstup určili podle nejpodobnější
varianty\cite{huang2014historical}. V~tomto přístupu je veškerá expertiza ze
strany člověka, a sice výběr množiny referenčních vzorků.

Velkým průlomem bylo použití skrytých
markovovských modelů (\textit{HMM}). Vychází se z~představy, že mluvčí předává
informaci (posloupnost písmen, či slov) zakódovanou v~kanálu akustického vlnění,
a naším úkolem je původní informaci rozkódovat.

Úlohu rozpoznávání řeči můžeme formalizovat takto: Na základě vstupní
posloupnosti hodnot akustického vlnění $A$ hledáme takovou posloupnost písmen
(\textit{characters}) $C$, aby pravděpodobnost $P(C|A)$ byla co největší, tedy:

\begin{equation}
argmax_{\vec{C}} P(C|A)
\end{equation}

Pravděpodobnost $P(C|A)$ ovšem dlouho nebylo jak odhadnout, proto se využilo
Bayesova pravidla:

\begin{equation}
P(C|A) = \over{P(A|C)*P(C)}{P(A)}
\end{equation}.

Pravděpodobnost vstupních dat je ve vztahu k odhadovanému modelu konstantní a
kladná, proto se jmenovatel zanedbává. Zbývá tedy odhadnout $P(A|C)$ a $P(C)$.
Pro to první se vžilo název \textit{akustický model (AM)}, pro to druhé
\textit{jazykový model (language model, LM)}.

Akustický model je právě tím místem, které zastávají skryté markovovské modely.
Jedná se o generativní modelování, tedy pro účely řešení úlohy předpokládáme, že
vstupní akustická sekvence je generována markovovským procesem.

Parametry, které HMM definují, jsou vymezení stavů v~prostoru vstupních dat a
přechodové pravděpodobnosti mezi stavy. Musí se tedy určit množina modelů a
prostor vstupních dat.

\subsection{Prostor vstupních dat}

Zvukový signál je velmi prostý: je to spojitá funkce času do reálných čísel.
Má-li se zaznamenat digitálně, volí se technika vzorkování \textit{(sampling)},
kdy se z~průběhu funkce v~čase, jehož spojitost či diskrétnost je otázkou mimo
rámec této práce, vybere vzorek v~rozestupu definované periody. Čím větší
vzorkovací frekvence, tím 1) větší věrnost při reprodukci, 2) vyšší tónovou
frekvenci lze reprezentovat a 3) větší náročnost na uložení a zpracování.

Vzorkovací frekvence se podle účelu záznamu pohybuje obvykle od 8~kHz pro
datově úsporný přenos hlasu do 96~kHz pro studiové zpracování hudby. Pro účely
rozpoznávání řeči se osvědčila vzorkovací frekvence 16~kHz jako minimum, ve
kterém je obsažena prakticky veškerá relevantní informace.

Jako vstupní data pro skryté markovovské modely nejsou prostá reálná
čísla\footnote{pro počítačovou implementaci jsou reálná čísla díky svému
nekonečnému desetinnému rozviji nereálná, pro se v~praxi pracuje s~tzv. čísly
s~plovoucí desetinnou čárkou (\textit{floating-point numbers}).} v~řádu tisíců
za sekundu praktická, pročež se signál nejdříve transformuje do jiné formy. Tato
část systému se zove \textit{front-end} a implementuje se nejčastěji pomocí
melfrekvenčních kepstrálních koeficientů \textit{(MFCC)} nebo řidčeji pomocí
perceptuální lineární predikce \textit{(PLP)}. Účelem není jen transformace do
praktičtějšího prostoru, ale též odstranění nerelevantní informace a normalizace
té relevantní.

Převod z~akustického vlnění do melfrekvenčních kepstrálních koeficientů
transformuje proud jednoho reálného čísla šestnáctkrát za milisekundu do proudu
reálněčíselného vektoru stokrát za sekundu. Běžně každý vektor kóduje časové
okno o délce čtyřicetiny sekundy a okna jsou od sebe vzdálena setinu sekundy,
takže se překrývají. Na každém časovém okně se provede diskrétní Fourierova
transformace a rozdělí se do frekvenčních oken podle škály
mel\cite{stevens1937scale} aplikováním trojúhelníkového filtru. Frekvenčních
oken bývá 12 a opět se překrývají. Frekvenční okna se s~rostoucí frekvencí
zvětšují tak, aby zůstávala konstantní v~jednotkách mel a aby tedy odpovídala
lidskému vnímání spektra. Hodnoty se logaritmují, opět aby byly
úměrnější lidskému vnímání hlasitosti. Jako třináctá hodnota se přidá buď
základní frekvence nebo častěji akustická energie. Poté se provede inferzní
diskrétní Fourierova transformace, podle čehož se kepstrum nazývá inverzí
začátku slova spektrum. Od těchto hodnot se na základě kontextu přidá první a
druhá derivace, čímž získáváme devětatřicetirozměrný reálněčíselný vektor každou
setinu sekundy.

\section{Technologie rozpoznávání řeči}

\section{Markovovské modely}

Až do druhé dekády druhého milénia byly nejlepší dostupnou technologií pro
rozpoznávání řeči skryté markovovské modely s~gaußovskými směsmi (GMM-HMM).
Architektura takového systému vypadá následovně:

\begin{enumerate}
\item{Diskrétní jednotkou vstupních dat je úsek přibližně o délce jedné věty.}
\item{Vstupní datum\footnote{Datum ve smyslu jednotného čísla od slova data,
z~latinského participia slova \textit{dare}, dát.} je zakódováno do posloupnosti
reálněčíselných vektorů, z~nichž každý odpovídá setině sekundy signálu.}
\item{}
\end{enumerate}

Pro získání počátečního přepisu bylo nutné sestavit
systém pro automatický přepis, z~historických důvodů častěji označovaný jako
rozpoznávání řeči. Rozpoznávání češtiny se věnovali mnozí přede mnou,
například Ircing et al. (2001)\cite{ircing2001large}, Psutka et al.
(2005)\cite{psutka2005automatic}, či Byrne et al. (1999)\cite{byrne1999large}.
V následujících odstavcích popíšu tvorbu rozpoznávače řeči pro korpus Karla
Makoně.

Zjednodušený řetězec vedoucí od~zvukových dat k~jejich přepisu v~našem případě
vypadá takto:\begin{enumerate}
\item{sběr trénovacích dat,}
\item{stavba akustického modelu,}
\item{stavba jazykového modelu,}
\item{automatické rozpoznávání.}
\end{enumerate}

První trénovací sadu jsem pořídil svépomocí přepisem asi 15 minut nahrávky
\texttt{85-05A}.

V~průběhu práce jsem sestavil dva zcela odlišné akustické modely: Jeden založený
na skrytých markovovských modelech a jeden založený na neuronových sítích.
Hlavním důvodem bylo to, že když jsem začínal, nebyly ještě hluboké neuronové
sítě tak rozšířené. Jsou ale i dvě další výhody, které použití markovovských
modelů opodstatňují: 1) Nepotřebují tolik trénovacích dat, takže se více hodí do
začátku, kde je přepsaná množina malá, a 2) umožňují získat přesné zarovnání
slov a hlásek na časové pozice ve zvukovém záznamu. Dosud neznám žádný nástroj
založený na hlubokých neuronových sítích, který by toto poskytoval.

Nejdříve popíšu výstavbu markovovského modelu a poté od
sekce~\ref{sec:deepspeech} se budu věnovat modelu založenému na neuronových
sítích.

\section{Základní tvorba akustického modelu}

Do~užšího výběru potenciálních platforem tvorby akustického modelu jsem zařadil
starší systém \textit{HTK}\footnote{HMM ToolKit; HMM = Hidden Markov Model.}\cite{young2002htk} a
modernější \textit{Kaldi}\cite{povey2011kaldi}. HTK pomyslný konkurz nakonec
vyhrál díky tomu, že můj konzultant Mgr. Nino Peterek, Ph.D. má s~tímto systémem
bohaté zkušenosti, z~nichž jsem mohl čerpat.

Akustický model jsem trénoval výhradně z~vlastních dat.
% Obětoval jsem tedy
% potenciální přínos většího množství trénovacích dat a upřednostnil trénování
% přímo na~konkrétního mluvčího.
%TODO: od kdy se vyplatí dělat model na konkrétního mluvčího?

Tvorba akustického modelu probíhala podle návodu v~manuálu k~HTK, \textit{HTK
Book}. V~hrubých rysech probíhá takto:

\begin{enumerate}

\item{Vytvoření počátečních modelů.}

Modeluje se skrytými markovovskými řetězci. Všechny fonémy se inicializují jako
shodné. Každý foném je reprezentován pěti stavy (vstupním, výstupním a třemi
vnitřními). Přechodové pravděpodobnosti se nastaví tak, aby byly možné jen
kýžené přechody, to jest ze~vstupního do~druhého a z~každého z~vnitřních stavů
do~sebe samého nebo do~následujícího. Konkrétní pravděpodobnosti nejsou
podstatné, ale použil jsem 60\% pro setrvání a 40\% pro postup ve~druhém a
třetím stavu a 70\% pro setrvání a 30\% pro postup ze~čtvrtého do~výstupního.
Střed a variance jsou určeny identicky podle globálních hodnot.

Kromě vlastních fonémů (viz níže sekci~\ref{sec:ac:fonetika}) přidám ještě foném
pro~ticho (\texttt{sil}).

Pro kódování používám formát MFCC s~první a druhou derivací, nultým koeficientem
a kepstrální normalizací (\texttt{MFCC\_0\_D\_A\_Z} v~notaci HTK).

Následují dvě iterace tréninku Baum-Welchovým algoritmem\cite{welch2003hidden}.

\item{Přidání modelu pro krátkou pauzu.}

Z~modelu pro ticho se odvodí model pro krátkou pauzu tak, že se povolí přechod
rovnou z~druhého do~čtvrtého stavu a zpět, aby byl model robustnější a mohl
modelovat pauzu mezi slovy, která je nezřídka nulová.

Trénuje se opět dvěma iteracemi BW-algoritmu.

\item{Nucené zarovnání a odvržení zmetkových vzorků.}

Pomocí Viterbiho algoritmu\cite{forney1973viterbi} se provede tzv.
\textit{forced alignment}, tzn. nucené zarovnání na~úrovni fonémů. Jinými slovy
určí se přesný čas, kde začíná a končí který foném. Při tom se určí hranice, pod
kterou když klesne \textit{likelihood} daného přepisu na~základě odpovídající
nahrávky, tato se z~trénovacích dat odstraní jako pravěpodobně vadná. Následují
další dvě iterace BW-algoritmu.

\item{Přepočítání variance.}

Variance modelů byla určena podle původní trénovací sady. Nyní jsme z~ní
vyřadili některé vzorky, proto proběhne její přepočtení, opět následované dvěma
trénovacími iteracemi.

\item{Přechod k~trifonémům}
\label{item:htktrain:triphones}

Z~nuceného zarovnání máme přepis obohacený o~konkrétní fonetické realizace. Z~té
se nyní snadno vytvoří přepis trifonémový tak, že ke každému fonému přidáme
jeho levý a pravý kontext, pokud nejsou na~začátku nebo na~konci věty.

Je-li fonémů 45, pak trifonémů je až $45^3 = 91125$. Ne všechny se v~trénovacích
datech objeví. V~praxi jich mám kolem 14 tisíc. Pokud by každý trifoném měl
vlastní separátní model, došlo by k~opačnému problému než v~případě monofonémů,
totiž že by celkový model měl příliš mnoho parametrů. Přechodové matice mohou
všechny trifonémy odvozené od jednoho monofonému sdílet. Avšak které trifonémy
mají sdílet varianci a které mají mít vlastní, je třeba rozhodnout opatrněji.

Pro určení, které modely je vhodné sloučit, používám rozhodovací stromy.
Na~základě předem definovaných kritérií se u~každého emitujícího stavu každé
skupiny trifonémů provede rozdělení na~dva shluky, což umožní zvýšení
\textit{log likelihood} dat. Vybere se kritérium, které log likelihood
zvýší nejvíce a postup se opakuje, dokud zvýšení neklesne pod~danou hranici.
Takto získané shluky se pak sloučí do jednoho logického trifonému.

\item{Štěpení mixtur}

Posledním krokem ve~zvětšování komplexity modelu je štěpení tzv.~\textit{mixtur}
(z~angl. \textit{mixtures}). Spočívá v~tom, že se přesněji modelují variantní
realizace jednotlivých fonémů. Daný foném v~jednom stavu HMM pak není modelován jednou gaußovskou
distribucí, nýbrž složením několika. Každá má svůj střed, svoji varianci a svoji
váhu, jejichž celkový součet musí být roven jedné.

Štěpí se vnitřní stavové modely jednotlivých fonémů. Optimální počet
mixtur je tedy potřeba zjistit pro trojnásobek počtu použitých trifonémů. To
jsou řádově tisíce až desítky tisíc. V~okamžiku psaní tohoto textu používám 8444
reálných trifonémů; 13746, počítám-li i ty virtuální. To znamená přes dvacet pět
tisíc distribucí, u~nichž je potřeba určit optimální počet mixtur.

Aby byl úkol aspoň aproximací dosažitelný, je třeba hledat efektivněji než
prohledáváním celého prostoru hrubou silou. První pomocí zde je, že modely jsou
na sobě více méně nezávislé: Nalezneme-li optimální počet mixtur pro jeden
z~nich, nemělo by to ovlivnit optimální počet mixtur u~jiného.

Rozštěpení u~jednoho modelu proběhne tak, že se mixtura s~největší vahou
rozštěpí na dvě totožné s~tím, že jedna dostane malinko větší váhu než druhá, aby se
při trénování mohly rozejít. To se provede u~všech vnitřích stavů všech
logických fonémů, t.j. u~všech markovovských modelů. Provedou se čtyři trénovací
iterace a úspěšnost se vyhodnotí na~sadě heldout.

Pokud u~některé mixtury klesne její váha pod~daný práh, vymaže se, čímž se
zamezí zbytečnému nárůstu parametrů, a není proto potřeba zkoušet štěpit
jednotlivé modely samostatně. Arci, štěpením modelů jednoho po druhém jsem nikdy nedosáhl lepšího
výsledku, než štěpením všech modelů najednou.

Závislost úspěšnosti na~počtu mixtur není monotónní, proto ve~štěpení pokračuji,
i když někdy úspěšnost klesne. Konkrétně zastavím štěpení, pokud úspěšnost
klesne o~více než 30\% oproti nejvyšší dosažené nebo pokud klesne více než
třikrát za~sebou, ne však když je mixtur méně než 16.

%Pokud je foném gaußiánem modelován dobře, rozdělení na dvě mixtury
%nijak nepomůže. Navíc pokud rozdělíme dostribuci příliš, dojde snadno
%k~přetrénování. Je proto potřeba nalézt optimální počet mixtur pro každý
%jednotlivý trifoném.

\end{enumerate}

\section{Segmentace}

Zpravidla jeden zvukový soubor odpovídá jednomu přetočení magnetofonové pásky,
obvyklá délka je tedy 45 až 120 minut. Takto dlouhé úseky nelze použít ani jako
trénovací příklady ani jako cíl automatického rozpoznávání.

Sofistikovanější segmentaci popisuji v~sekci~\ref{sec:segmenty}. Pro účely
vývoje iniciálního systému automatického přepisu jsem však použil jednodušší
metodu:

Celá aplikace je pojata jako nástroj pro~zdokonalování automatického přepisu,
takže vychází z~předpokladu, že nějaký přepis již existuje. Vycházeje z~téhož
předpokladu při~segmentaci, realizoval jsem ji tak, že zvukový soubor se rozdělí
na~úseky odpovídající jednotlivým větám v~přepisu, ne však delší než patnáct
sekund. Pokud by věta byla delší, rozdělí se u nejbližšího slova
před~patnáctisekundovou hranicí.

V~případě, že pro daný záznam zatím žádný přepis neexistuje, rozdělí se naivně
na~patnáctisekundové úseky.

\section{Fonetika}
\label{sec:ac:fonetika}

\subsection{Fonetický přepis}

Trénovací data pro akustické modelování pomocí HTK mají formu párů
parametrizovaných zvukových souborů (v~mém případě MFCC) a textových souborů,
obsahujících fonetický přepis. Ten se může získat různými způsoby. Používám
upravenou metodu od Psutky et al.\cite{psutka2004development} Pro podrobnější
popis získávání fonetického přepisu viz
sekci~\ref{ssec:porizeni-fonetickeho-prepisu}.

\subsection{Fonémy}

Používám základní fonémy českého jazyka\cite{palkova1992fonetika}
reprezentované pomocí PACal\cite{nouza1997phonetic}. Kromě základních fonémů
používám dvojhlásky, ticho a krátkou pauzu. Ráz (glotální plozivu) nevyznačuji,
jakož ani neřečové události.
V~tabulce~\ref{tab:phones} jsou použité fonémy uvedeny.

\begin{table}[htpb]
%\fontspec{DoulosSIL}
\begin{center}
\begin{tabular}{|l|l|l||l|l|l|}
\hline
IPA                        & PACal & grafém & IPA & PACal & grafém \\
\hline
\textipa{a}                & a   & a      & \textipa{M}           & mg  & tra\underline{m}vaj \\
\textipa{a:}               & aa  & á      & \textipa{n}           & n   & \underline{n}e \\
\textipa{\t*{aU}}          & aw  & au     & \textipa{N}           & ng  & ta\underline{n}k \\
\textipa{b}                & b   & b      & \textipa{\textltailn} & nj  & \v{n} \\
\textipa{\t{ts}}           & c   & c      & \textipa{o}           & o   & o \\
\textipa{\t{tS}}           & ch  & č      & \textipa{o:}          & oo  & ó \\
\textipa{d}                & d   & d      & \textipa{\t*{oU}}     & ow  & ou \\
\textipa{\textbardotlessj} & dj  & \v{d}  & \textipa{p}           & p   & p \\
\textipa{\t{dz}}           & dz  & dz     & \textipa{r}           & r   & r \\
\textipa{\t{dZ}}           & dzh & dž     & \textipa{\|'{\r*{r}}} & rsh & t\underline{\v{r}}i \\
\textipa{E}                & e   & e      & \textipa{\|'r}        & rzh & \underline{\v{r}}íz \\
\textipa{E:}               & ee  & é      & \textipa{s}           & s   & s \\
\textipa{\t*{eU}}          & ew  & eu     & \textipa{S}           & sh  & š \\
\textipa{f}                & f   & f      & \textipa{t}           & t   & t \\
\textipa{g}                & g   & g      & \textipa{c}           & tj  & \v{t} \\
\textipa{H}                & h   & h      & \textipa{U}           & u   & u \\
\textipa{I}                & i   & i      & \textipa{u:}          & uu  & ú, \r{u} \\
\textipa{i:}               & ii  & í      & \textipa{v}           & v   & v \\
\textipa{j}                & j   & j      & \textipa{x}           & x   & ch \\
\textipa{k}                & k   & k      & \textipa{z}           & z   & z \\
\textipa{l}                & l   & l      & \textipa{Z}           & zh  & ž \\
\textipa{m}                & m   & \underline{m}ák
                                          &        & sil & \\
                           &     &        &        & sp  & \\
\hline
\end{tabular}
\caption{Použité fonémy: IPA, PACal a nejčastější odpovídající
grafém.}\label{tab:phones}
\end{center}
\end{table}
%\normalfont

V~závislosti na~množství trénovacích dat bylo vhodné nahradit některé fonémy
častějšími podobnými. V~tabulce~\ref{tab:phonesed} jsou záměny vyčísleny.
\begin{table}[htpb]
%\fontspec{DoulosSIL}
\begin{center}
\begin{tabular}{|r|l|l||l|l|}
\hline
&
\multicolumn{2}{|c||}{před záměnou} &
\multicolumn{2}{|c|}{po záměně} \\
\hline
& IPA & PACal & IPA & PACal \\
\hline
    & \textipa{M}       & mg & \textipa{m} & m \\
    & \textipa{\t*{aU}} & aw & \textipa{a U} & a u \\
    & \textipa{o:} & oo & \textipa{o} & o \\
\** & \textipa{\t{dz}}  & dz & \textipa{\t{ts}} & c \\
    & \textipa{\t{dz}}  & dzh & \textipa{\t{tS}} & ch \\
\** & \textipa{\t*{eU}} & ew & \textipa{E U} & e u \\
\hline
\end{tabular}
\caption{Použité záměny fonémů; hvězdičkou jsou vyznačeny záměny použité ještě
v~době psaní textu.}\label{tab:phonesed}
\end{center}
\end{table}
%\normalfont

\section{Rozdělení dat}
\label{sec:asr:rozdeleni-dat}

Pro natrénování modelu strojovým učením je potřeba trénovacích dat a pro
vyhodnocení jeho úspěšnosti dat testovacích, která ve~fázi trénování nesmí být
algoritmem spatřena. Při trénování samotném se pak mnohdy používá vyhrazených,
tzv.~\textit{heldout} dat\footnote{Často zaměňovaných s~vývojovou testovací sadou
označovanou běžně jako \textit{dev} / \textit{dtest}.} pro průběžné měření úspěšnosti. V~případě trénování
akustického modelu s~použitím HTK je tomu nejinak. Heldout data jsou používána
pro zjištění optimálního počtu mixtur modelů jednotlivých fonémů a testovací
pro závěrečné vyhodnocení.

Anotovaná data mi přibývala velice pozvolna. Začínal jsem s~několika minutami,
ovšem přírůstky byly časté. Nemohl jsem si tedy dovolit udělat od~začátku pevnou
testovací sadu, kterou bych používal po~celou dobu provádění experimentů. Místo
toho jsem s~každou novou dávkou anotovaných dat celou sadu rozdělil podle vět
v~poměru 18:1:1 do trénovací, heldout a testovací sady. Tak jsem měl neustále
vyvážený poměr jednotlivých datových sad. Zřejmou velkou nevýhodou bylo, že
nešlo spolehlivě porovnávat výsledky jednotlivých experimentů vzhledem
k~variabilní testovací sadě.

Až když jsem měl několik desítek hodin anotovaných dat, vyhradil jsem si fixní
testovací sadu. Běžně se testovací sada vybere jako náhodná podmnožina vzorků
z~trénovací sady tak, aby měla kýženou velikost. V~mém případě vzorků zvíci
hodinových nahrávek jsem sadu určil manuálně jako úsek druhé až jedenácté minuty
(tedy deset minut, vždy jednu minutu po~začátku) v~pěti nahrávkách,
\begin{enumerate}
\item{jedné kazety z~roku 1976,}
\item{jedné z~roku 1982,}
\item{jedné z~roku 1986,}
\item{jedné z~roku 1990 a}
\item{jednoho nedatovaného kotouče.}
\end{enumerate}

Sadu heldout nyní vybírám jako každou čtyřicátou větu. Z~každé dvacáté jsem
snížil na~polovic nejen abych neplýtval trénovacími daty, nýbrž také protože
vyhodnocování mixtur zabírá při trénování zdaleka nejvíce času, a ten je přímo
úměrný velikosti sady heldout.

\section{Spojování trifonémů}

Pro slučování modelů jednotlivých trifonémů, jak zmiňuje
bod~\ref{item:htktrain:triphones} seznamu kroků trénování pomocí~HTK, je
zapotřebí rozhodovacích stromů. Pro jejich tvorbu je potřeba ručně vytvořit
otázky, na jejichž základě bude algoritmus dělit fonémy do shluků. K~tvorbě
otázek můžeme použít lingvisticky motivovanou kategorizaci v~naději, že aspoň
některé lingvistikou definované kategorie budou z~pohledu trénovacích dat tvořit
konzistentní shluky. Pro tvorbu otázek jsem vycházel z~předlohy pro
angličtinu, jak je uvedeno v~HTK Book, a z~kategorizace českých hlásek na Wikipedii
(\texttt{https://cs.wikipedia.org/wiki/Fonologie~češtiny}).
% TODO otázky do apendixu

\section{Experiment s kepstrální normalizací}
\label{sec:mfcc-norm}

Kepstrální normalizace je standardní technikou pro kompenzaci různorodých
akustických podmínek v~rámci trénovacích a testovacích dat, viz Viikki a Laurila
(1998)\cite{viikki1998cepstral}. Princip této techniky spočívá v~tom, že se ode
všech melfrekvenčních kepstrálních koeficientů odečte jejich průměr z~akusticky
konzistentního úseku. Já toto poněkud hrubiánsky činím na celých nahrávkách,
které nejsou vždy akusticky konzistentní. Často však ano a nalezení akusticky
podobných množin je jedním z~mých plánů pro budoucí práci.\footnote{Tato úloha
je již vyřešena a popsána v~sekci~\ref{sec:akustika:metrika} a následující.}

Nabízí se však otázka, zda má smysl odečítat průměr z~celé nahrávky, nebo by to
mělo být jen z~řečových událostí, tedy s~vynechaným tichem (šumem, hluky atd.)
Tato idea, přišedší ke mně od dr. Davida Klusáčka, mne zaujala natolik, že jsem se
ji pokusil ověřit. Vytvořil jsem proto metadata s~časovými pozicemi všech
izolovaných řečových událostí na základě zarovnaného automatického přepisu a sadu skriptů
pro manipulaci se soubory MFCC.

Ke každému souboru MFCC jsem vytvořil kopii, ze které
jsem vynechal všechny fonémy \texttt{sil} a \texttt{sp}. Průměry kepstrálních
koeficientů jsem pak spočetl na těchto kopiích a odečetl je od hodnot
v~originálech. Trénování i testování jsem pak prováděl na takto upravených
souborech místo standardní normalizace, jak ji poskytuje systém HTK.

Celkový přínos pro úspěšnost rozpoznávání byl nulový, ale aparát pro dekódování
a manipulaci souborů MFCC považuji za vítaný vedlejší produkt.

\section{Aktivní učení}

Aktivní učení spočívá ve vhodném výběru trénovacích dat, viz např. Cohn
(1996)\cite{cohn1996active}. V~mém případě trénovací sada postupně roste a nabízí
se tedy využít techniky aktivního učení tak, aby se získávala co nejvhodnější
trénovací data.

Podnikl jsem experiment, ve kterém jsem ve webovém rozhraní ke sběru trénovacích
dat (viz kapitolu~\ref{kap:webove-rozhrani}) slova s~nízkou {\em confidence
measure (c.m.)} (pod 0,3) podtrhl červenou přerušovanou čarou, jejíž sytost spojitě rostla
s~klesající c.m. Instruoval jsem pak uživatele aplikace, aby přednostně
přepisovali věty, které jsou opticky co nejčervenější. Bohužel přirozené puzení
uživatelů přepisovat nahrávku kompletně a lineárně od začátku způsobilo, že
přepisů, kde se tato instrukce dodržuje, je zcela mizivé množství.

Druhý experiment spočíval v~tom, že webová aplikace sama vybírala věty pro
přepis na základě toho, kolik obsahovala slov s~nízkou c.m. Uživatelé pak byli
instruováni, aby nahrávku jen poslouchali, a opravu vložili, až když se
přehrávání samo přeruší. Tento pokus skončil ještě palčivějším neúspěchem, neboť
změna v~chování aplikace byla pro uživatele natolik nepříjemná, že jsem je
raději navrátil do původního.

\section{Rozšíření trénovací množiny}
\label{sec:confident}

Skóre confidence measure se dá využít ještě jiným způsobem: lze vybrat všechny
úseky v~korpusu kromě testovací sady\footnote{K zamyšlení: je zde opravdu nutné
vynechat testovací data?}, kde automatický přepis uvádí vysokou míru
c.m. a přidat tyto úseky do trénovací množiny. Tento experiment jsem provedl
tak, že minimální délku úseku jsem stanovil na 1 sekundu, minimální počet
obsažených fonémů na 10 a minimální c.m. na 0,6. Práh 0,6 jsem určil namátkovou
kontrolou, která poukazovala na zanedbatelnou chybovost takových úseků. Celkem
tento výběr poskytl 99 hodin audia, tedy 10\% celého korpusu.
Chybovost rozpoznávání se statisticky významně nezměnila, za to doba trénování
se zvýšila citelně.

\section{Neuronové sítě}
\label{sec:deepspeech}

V~průběhu psaní této disertace se rozšířilo používání hlubokých neuronových sítí
snad ve všech oblastech strojového učení, viz např. LeCun
(2015)\cite{lecun2015deep}, Hinton (2012)\cite{hinton2012deep}. Toto neminulo ani
rozpoznávání řeči, konceptuelně již dávno před tím, viz Morgan
(1995)\cite{morgan1995neural}. Gaußovské mixtury
přestaly být state of the art a systémy založené na hlubokých neuronových sítích
(DNN) skýtají mnohem větší úspěšnosti díky tomu, že lépe modelují fenomén
fonémů. Umožňují i přímo modelovat grafémy na základě parametrizovaného zvuku, tedy
přeskočit vrstvu výslovnosti.

Nezisková organizace Mozilla vydala vlastní svobodný nástroj pro rozpoznávání
řeči DeepSpeech\cite{hannun2014deep} založený na
TensorFlow\cite{abadi2016tensorflow}.

Akustický model jsem na něm natrénoval dvojí: 1) čistě na manuálních přepisech
Makoňových nahrávek (v~době psaní 100 hodin), 2) na agregované sadě popsané
v~sekci~\ref{sec:csasr:results}.

Model natrénovaný jen na Makoňových nahrávkách zkonvergoval po osmi epochách a
dosáhl word error rate 19,2\% na testovací sadě. Druhý model jsem vytvořil tak,
že jsem nejprve trénoval na agregované trénovací sadě s~použitím Makoňovy
sady heldout pro validaci. Tato část zkonvergovala po 15 epochách a dosáhla WER
16,6\%. Následně jsem pokračoval v~tréninku na Makoňových nahrávkách. Tato část
zkonvergovala po dvou epochách a konečné skóre bylo 13,0\% WER.

Dokud jsem ale trénoval s~číslicemi, viz sekci~\ref{sec:svolocz:cislovky},
dosáhl tento model výrazně nižší úspěšnosti s~téměř dvojnásobnou chybovostí
27,3\% resp. 23,5\% WER.
Na testovací sadě měl tedy vyšší úspěšnost model trénovaný jen na 100h Makoňových
nahrávek se standardní abecedou, předče model trénovaný na 1500 hodinách na
abecedě rozšířené o číslice.


Nejmarkantnější zlepšení přináší robustní model na velice poškozených nahrávkách, které jsem
v~době výběru testovací sady ještě neměl k~dispozici, any byly digitalizovány
mnohem později. Jedná se hlavně o nahrávky pořizované při nízké rychlosti
převíjení pásky, zmiňované jednak v~sekci~\ref{sec:akustika:kompenzace} a jednak
v~sekcích~\ref{sec:data:rec} a \ref{sec:data:digitisation}.

Na minutovém úseku jedné z~nejpoškozenějších nahrávek, který jsem
přepsal, má první model WER 94,1\%, zatímco robustní model má WER
75,8\%. Porovnání na větším, asi pětiminutovém úseku je uvedeno
v~sekci~\ref{sec:akustika:vyhodnoceni}.

Bohužel vinou přímého mapování z~parametrizovaného audia na grafémy přicházíme o
možnost zarovnání na úrovni fonémů, takže je nutno výstup nechat zarovnat
v~další iteraci, aby se umožnilo synchronní přehrávání ve webovém rozhraní.

\section{Jazykový model}
\label{sec:jazykovy-model}

Jazykový model obecně je pravděpodobnostní rozdělení posloupností slov
v~přirozeném jazyce\cite{ponte1998language}. V~kontextu rozpoznávání řeči je tandemovým
partnerem akustického modelu\cite{jelinek1990self}. Teprve kombinace akustického
a jazykového modelu určí výsledné slovo, které se na dané pozici rozpozná jako
nejpravděpodobnější.

Výběr jazykového modelu je omezen nástrojem pro rozpoznávání. Lze zvolit pouze
takový model, který nástroj dokáže využít. Všechny nástroje, které jsem použil,
podporují N-gramové jazykové modely: HVite bigramový, Julius až trigramový a
DeepSpeech libovolného řádu.

Pro trénování jazykového modelu mám k dispozici čtyři druhy dat:
\begin{enumerate}
\item{Obecné české texty,}
\item{Makoňovy spisy,}
\item{manuální přepisy nahrávek,}
\item{automatické přepisy.}
\end{enumerate}

Každá z~těchto kategorií skýtá různé množství textu a různou věrnost
modelovanému materiálu. Nejvěrnější jsou samozřejmě manuální přepisy Makoňových
nahrávek, kterých je nejméně. V~okamžiku psaní tohoto textu je to přesně 715 285
slov. Automatické přepisy, jejichž přínos pro jazykové modelování je nejasný,
představují 6 795 325 slov. Makoňovy spisy obsahují 3 328 720 slov. Obecné české
texty jsou nejdostupnější z~těchto komodit. Nejobsáhlejší dostupný korpus, který
jsem nalezl, je Mononews z WMT\cite{wmt19} obsahující 1 019 497 060 slov.

Manuálním testováním jsem dospěl k~vahám $1 : 2000 : 7999 : 0$ pro korpusy
v~pořadí z~číslovaného seznamu výše. Aplikuji vyhlazování technikou
Knesser-Ney\cite{chen1999empirical}, jak je zabudována do nástroje pro trénink
jazykových modelů KenLM\cite{heafield2011kenlm}.

Je třeba podotknout, že u manuálních přepisů dochází k~jednomu
nežádoucímu jevu. Přepisy se pořizují tak, aby byly maximálně věrné tomu, co je
vyřčeno. Proto se doslova... vlastně do hlásky přepisují i přebrepty a zadrhnutí.
Je otázkou, zda takové jevy chceme mít v~jazykovém modelu. Aniž bych se na ni
pokoušel poskytnout definitivní odpověď, můj přístup, jak se s~tímto vypořádat,
je, instruovat uživatele těmito pokyny: 1) Každé slovo, po kterém následuje přerušení toku
mluvy doplnit třemi tečkami, 
2) pokud se mluvčí zadrhne uprostřed slova nebo vysloví něco, co není slovem,
připojit k~tomuto útvaru pomlčku\footnote{Standardní postup, se kterým jsem se
seznámil až později, je místo pomlčky použít symbol \texttt{+}.}. Například ve větě {\em ,,To je ta relativnost
dobrého a zlého, tak kdybychom... to je tam jinak postaveno.``} patří tři tečky
za slovo {\em kdybychom}. Ve větě {\em ,,To je první š- špatný pohled, chybný pohled na rodiče a na
předcházející generaci.``} patří pomlčka za vyslovené {\em š}, za kterým
teprve následuje vyslovené slovo {\em špatný}.

Při stavbě jazykového modelu toto značení umožní, aby se věta při setkání
s~takovým slovem ukončila nebo aby se takové slovo přeskočilo.

\section{Úspěšnost}
\label{sec:evaluace}

Poslední naměřená word error rate markovovského akustického modelu s~výše zmíněným
jazykovým modelem je 46,3\%.

Vzhledem k~tomu, že mi v~průběhu projektu rostla trénovací sada, určil jsem testovací sadu
až v~průběhu projektu. Chybí v~ní přepisy těch
nejméně srozumitelných nahrávek, které byly digitalizovány až po provedení
většiny experimentů, a navíc k~nim pořizovat ruční přepisy je velice nesnadné.

Tabulka~\ref{tab:asr-scores} uvádí nejdůležitější milníky ve word error rate. Je
s~podivem, že model dotrénovaný na Makoňových nahrávkách má na obecné testovací
množině větší úspěšnost (v~tabulce tučně) než výchozí model trénovaný na všech datech
(viz tabulku~\ref{tab:csasr:results}). Dalo by se čekat, že
když se po konvergenci na obecné trénovací množině aplikují ještě
další trénovací epochy na jiných specifických datech, měla by úspěšnost stoupnout na
oněch specifických datech a poklesnout na datech obecných. Příčinu tohoto jevu
jsem dosud neměl příležitost prozkoumat.

\begin{table}[htpb]
\begin{center}
\begin{tabular}{|l|l|l|l|}
\hline
model & GMM & \makecell{ DNN trénovaný\\ na Makoňovi } & \makecell{ DNN trénovaný\\ na různých sadách } \\
\hline
\makecell{standardní testovací\\ množina (50min)} & 46,3\% & 19,2\% & 13,0\% \\ \hline
\makecell{5 minut\\ přebuzených záznamů} & & 45,0\% & 34,8\% \\ \hline
\makecell{ 5 minut\\ záznamů pořízených\\ nízkou rychlostí } & & 68,5\% & 42,1\% \\ \hline
\makecell{ 1 minuta obzvláště\\ nesrozumitelného záznamu } & & 94,1\% & 75,9\% \\ \hline
\makecell{agregovaná testovací\\ sada z~různých dat} & & 77,3\% & \textbf{22,2\%} \\ \hline %25,3 s číslicema
\end{tabular}
\caption{Chybovosti tří důležitých modelů na různých testovacích sadách.}\label{tab:asr-scores}
\end{center}
\end{table}

Je úspěšnost nízká nebo vysoká? V~roce 2016 publikovali Mizera et
al.\cite{mizera2016kaldi} sadu receptů na rozpoznávání řeči pro češtinu.
Uvádějí jako state of the art techniky GMM-HMM a DNN-HMM a word error rate pro
jednotlivé recepty mezi 8,49 a 48,47 podle povahy dat. Úspěšnost na korpusu
Karla Makoně v~tomto porovnání tedy nijak nepřekvapuje, obzvláště s~přihlédnutím
k~velké akustické variabilitě materiálu.
